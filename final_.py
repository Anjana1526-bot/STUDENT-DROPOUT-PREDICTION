# -*- coding: utf-8 -*-
"""Final .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PFcW1gCd91mVojw9-qODbvmKTJ8TntEy
"""

# Student Dropout Prediction System
# Advanced implementation with XGBoost, LSTM, SMOTE, SHAP and Bayesian Optimization

# Install required packages
!pip install xgboost shap imbalanced-learn scikit-optimize ipywidgets matplotlib seaborn tensorflow pandas numpy scikit-learn yellowbrick
!jupyter nbextension enable --py widgetsnbextension

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from sklearn.linear_model import LogisticRegression
import xgboost as xgb
from imblearn.over_sampling import SMOTE
import shap
from skopt import BayesSearchCV
from skopt.space import Real, Integer
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout
from tensorflow.keras.callbacks import EarlyStopping
import ipywidgets as widgets
from ipywidgets import HBox, VBox, Layout
import io
import time
import warnings
from IPython.display import display, HTML, clear_output
warnings.filterwarnings('ignore')

# Define the main class for the Student Dropout Prediction System
class StudentDropoutPredictor:
    def __init__(self):
        self.data = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.X_train_resampled = None
        self.y_train_resampled = None
        self.models = {}
        self.results = {}
        self.temporal_features = []
        self.scaler = StandardScaler()
        self.le = LabelEncoder()
        self.explainer = None
        self.semester_columns = []
        self.lstm_model = None
        self.current_model = None

    def load_data(self, file):
        """Load the dataset from uploaded file"""
        try:
            # Check if any file is uploaded
            if file:
                # Extract the first file from the uploaded files
                uploaded_file = list(file.values())[0]  # Get the first uploaded file
                file_content = uploaded_file['content']  # Get the content
                file_name = uploaded_file['name']  # Get the name

                # Load the data based on the file extension
                if file_name.endswith('.csv'):
                    self.data = pd.read_csv(io.BytesIO(file_content))
                elif file_name.endswith(('.xls', '.xlsx')):
                    self.data = pd.read_excel(io.BytesIO(file_content))
                else:
                    raise ValueError("Unsupported file format. Please upload a CSV or Excel file.")

                # Display data info
                print(f"Dataset loaded successfully. Shape: {self.data.shape}")
                print("\nData Sample:")
                display(self.data.head())
                print("\nData Info:")
                self.data.info()
                print("\nSummary Statistics:")
                display(self.data.describe())
                print("\nMissing Values:")
                display(self.data.isnull().sum())

                # Check for class imbalance
                if 'dropout' in self.data.columns:
                    target_col = 'dropout'
                elif 'Target' in self.data.columns:  # Adjusted to match your dataset
                    target_col = 'Target'
                else:
                    print("Warning: Could not identify target column. Please rename your target column to 'dropout' or 'Target'.")
                    return

                # Class distribution
                class_counts = self.data[target_col].value_counts()
                dropout_rate = class_counts[1] / len(self.data) * 100 if 1 in class_counts.index else 0
                print(f"\nClass Distribution:\n{class_counts}")
                print(f"Dropout Rate: {dropout_rate:.2f}%")

                # Visualize class distribution
                plt.figure(figsize=(8, 6))
                sns.countplot(x=target_col, data=self.data)
                plt.title('Class Distribution')
                plt.ylabel('Count')
                plt.xlabel('Dropout (1 = Yes, 0 = No)')
                plt.show()

                return True
            else:
                print("No file uploaded.")
                return False
        except Exception as e:
            print(f"Error loading data: {str(e)}")
            return False

    def preprocess_data(self, test_size=0.2, random_state=42, target_col='dropout', temporal=True):
        """Preprocess the data for model training"""
        try:
            # If target column is not 'dropout', check for alternatives
            if target_col not in self.data.columns:
                if 'Target' in self.data.columns:
                    target_col = 'Target'
                else:
                    print("Warning: Target column not found. Please specify the correct target column name.")
                    return False

            # Identify temporal features (semester-wise features)
            if temporal:
                self.semester_columns = []
                # Try to automatically identify semester columns (assuming they follow patterns like 'sem1_', 'semester1_', etc.)
                for col in self.data.columns:
                    if col.startswith(('sem', 'semester', 'term')) and '_' in col:
                        prefix = col.split('_')[0]
                        self.semester_columns.append(prefix)

                self.semester_columns = list(set(self.semester_columns))

                if not self.semester_columns:
                    print("No semester columns detected. Treating data as non-temporal.")
                else:
                    print(f"Detected semester columns: {self.semester_columns}")

            # Separate features and target
            X = self.data.drop(columns=[target_col])
            y = self.data[target_col]

            # Handle categorical variables
            categorical_cols = X.select_dtypes(include=['object', 'category']).columns
            for col in categorical_cols:
                X[col] = self.le.fit_transform(X[col])

            # Split the data
            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
                X, y, test_size=test_size, random_state=random_state, stratify=y
            )

            # Scale the features
            self.X_train = pd.DataFrame(
                self.scaler.fit_transform(self.X_train),
                columns=X.columns
            )
            self.X_test = pd.DataFrame(
                self.scaler.transform(self.X_test),
                columns=X.columns
            )

            # Apply SMOTE to handle class imbalance
            smote = SMOTE(random_state=random_state)
            self.X_train_resampled, self.y_train_resampled = smote.fit_resample(self.X_train, self.y_train)

            print("Data preprocessing completed successfully.")
            print(f"Original training set shape: {self.X_train.shape}, Class distribution: {pd.Series(self.y_train).value_counts()}")
            print(f"Resampled training set shape: {self.X_train_resampled.shape}, Class distribution: {pd.Series(self.y_train_resampled).value_counts()}")

            # Reshape data for LSTM if temporal features are present
            if self.semester_columns:
                print("Preparing temporal data for LSTM...")
                self.prepare_temporal_data()

            return True
        except Exception as e:
            print(f"Error preprocessing data: {str(e)}")
            return False

    def prepare_temporal_data(self):
        """Prepare temporal data for LSTM model"""
        self.temporal_features = []
        self.temporal_X_train = []
        self.temporal_X_test = []

        # Extract and organize features by semester
        # This is a simplified approach - you may need to adjust based on your actual data structure
        for col in self.X_train.columns:
            for sem in self.semester_columns:
                if col.startswith(sem + '_'):
                    self.temporal_features.append(col)

        # If temporal features were found, reshape for LSTM
        if self.temporal_features:
            num_semesters = len(self.semester_columns)
            num_features_per_semester = len(self.temporal_features) // num_semesters

            # Reshape data: (samples, time steps, features)
            self.temporal_X_train = np.zeros((len(self.X_train_resampled), num_semesters, num_features_per_semester))
            self.temporal_X_test = np.zeros((len(self.X_test), num_semesters, num_features_per_semester))

            for i, sem in enumerate(self.semester_columns):
                sem_features = [f for f in self.temporal_features if f.startswith(sem + '_')]
                if sem_features:
                    self.temporal_X_train[:, i, :] = self.X_train_resampled[sem_features].values
                    self.temporal_X_test[:, i, :] = self.X_test[sem_features].values

            print(f"Temporal data prepared. Shape: {self.temporal_X_train.shape} (samples, semesters, features per semester)")
        else:
            print("No temporal features found. LSTM model will not be used.")

    def train_baseline_model(self):
        """Train the baseline Logistic Regression model"""
        start_time = time.time()
        print("Training Logistic Regression baseline model...")

        # Create and train the model
        lr_model = LogisticRegression(max_iter=1000, random_state=42)
        lr_model.fit(self.X_train, self.y_train)

        # Make predictions
        y_pred = lr_model.predict(self.X_test)

        # Evaluate the model
        report = classification_report(self.y_test, y_pred, output_dict=True)
        cm = confusion_matrix(self.y_test, y_pred)

        # Calculate ROC curve
        y_pred_proba = lr_model.predict_proba(self.X_test)[:, 1]
        fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)

        execution_time = time.time() - start_time

        # Store results
        self.models['logistic_regression'] = lr_model
        self.results['logistic_regression'] = {
            'report': report,
            'confusion_matrix': cm,
            'execution_time': execution_time,
            'roc_auc': roc_auc,
            'fpr': fpr,
            'tpr': tpr
        }

        print(f"Baseline Logistic Regression model trained in {execution_time:.3f} seconds")
        print(f"Test set accuracy: {report['accuracy']:.4f}")
        print(f"ROC AUC: {roc_auc:.4f}")
        print("Classification Report:")
        print(classification_report(self.y_test, y_pred))

        # Plot confusion matrix
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Not Dropout', 'Dropout'],
                    yticklabels=['Not Dropout', 'Dropout'])
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title('Confusion Matrix - Logistic Regression')
        plt.show()

    def train_xgboost_model(self, optimize=True):
        """Train the XGBoost model with optional Bayesian optimization"""
        start_time = time.time()
        print("Training XGBoost model...")

        if optimize:
            print("Using Bayesian optimization to find optimal hyperparameters...")

            # Define the search space
            search_spaces = {
                'learning_rate': Real(0.01, 0.3),
                'max_depth': Integer(3, 10),
                'min_child_weight': Integer(1, 10),
                'gamma': Real(0, 1),
                'subsample': Real(0.5, 1.0),
                'colsample_bytree': Real(0.5, 1.0),
                'n_estimators': Integer(50, 300)
            }

            # Create the XGBoost model
            xgb_model = xgb.XGBClassifier(
                objective='binary:logistic',
                random_state=42,
                use_label_encoder=False,
                eval_metric='logloss'
            )

            # Perform Bayesian optimization
            bayes_search = BayesSearchCV(
                xgb_model,
                search_spaces,
                n_iter=10,  # Reduced for faster execution in Colab
                cv=3,        # Reduced for faster execution
                n_jobs=-1,
                random_state=42,
                scoring='roc_auc'
            )

            bayes_search.fit(self.X_train_resampled, self.y_train_resampled)

            # Get the best model
            xgb_model = bayes_search.best_estimator_
            print(f"Best hyperparameters: {bayes_search.best_params_}")
        else:
            # Use default hyperparameters
            xgb_model = xgb.XGBClassifier(
                objective='binary:logistic',
                random_state=42,
                use_label_encoder=False,
                eval_metric='logloss'
            )
            xgb_model.fit(self.X_train_resampled, self.y_train_resampled)

        # Make predictions
        y_pred = xgb_model.predict(self.X_test)

        # Evaluate the model
        report = classification_report(self.y_test, y_pred, output_dict=True)
        cm = confusion_matrix(self.y_test, y_pred)

        # Calculate ROC curve
        y_pred_proba = xgb_model.predict_proba(self.X_test)[:, 1]
        fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)

        execution_time = time.time() - start_time

        # Store results
        self.models['xgboost'] = xgb_model
        self.results['xgboost'] = {
            'report': report,
            'confusion_matrix': cm,
            'execution_time': execution_time,
            'roc_auc': roc_auc,
            'fpr': fpr,
            'tpr': tpr
        }

        # Create SHAP explainer
        self.explainer = shap.TreeExplainer(xgb_model)

        print(f"XGBoost model trained in {execution_time:.3f} seconds")
        print(f"Test set accuracy: {report['accuracy']:.4f}")
        print(f"ROC AUC: {roc_auc:.4f}")
        print("Classification Report:")
        print(classification_report(self.y_test, y_pred))

        # Plot confusion matrix
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Not Dropout', 'Dropout'],
                    yticklabels=['Not Dropout', 'Dropout'])
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title('Confusion Matrix - XGBoost')
        plt.show()

        # Set as current model
        self.current_model = 'xgboost'

    def train_lstm_model(self):
        """Train the LSTM model for temporal data"""
        if not hasattr(self, 'temporal_X_train') or self.temporal_X_train is None or len(self.temporal_X_train) == 0:
            print("No temporal data available for LSTM. Run preprocess_data with temporal=True first.")
            return

        start_time = time.time()
        print("Training LSTM model...")

        # Define the LSTM model architecture
        self.lstm_model = Sequential([
            LSTM(64, input_shape=(self.temporal_X_train.shape[1], self.temporal_X_train.shape[2]), return_sequences=True),
            Dropout(0.2),
            LSTM(32),
            Dropout(0.2),
            Dense(16, activation='relu'),
            Dense(1, activation='sigmoid')
        ])

        # Compile the model
        self.lstm_model.compile(
            optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy']
        )

        # Early stopping to prevent overfitting
        early_stopping = EarlyStopping(
            monitor='val_loss',
            patience=5,
            restore_best_weights=True
        )

        # Train the model
        history = self.lstm_model.fit(
            self.temporal_X_train, self.y_train_resampled,
            epochs=20,
            batch_size=32,
            validation_split=0.2,
            callbacks=[early_stopping],
            verbose=1
        )

        # Make predictions
        y_pred_proba = self.lstm_model.predict(self.temporal_X_test)
        y_pred = (y_pred_proba > 0.5).astype(int).flatten()

        # Evaluate the model
        report = classification_report(self.y_test, y_pred, output_dict=True)
        cm = confusion_matrix(self.y_test, y_pred)

        # Calculate ROC curve
        fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)

        execution_time = time.time() - start_time

        # Store results
        self.models['lstm'] = self.lstm_model
        self.results['lstm'] = {
            'report': report,
            'confusion_matrix': cm,
            'execution_time': execution_time,
            'roc_auc': roc_auc,
            'fpr': fpr,
            'tpr': tpr,
            'history': history.history
        }

        print(f"LSTM model trained in {execution_time:.3f} seconds")
        print(f"Test set accuracy: {report['accuracy']:.4f}")
        print(f"ROC AUC: {roc_auc:.4f}")
        print("Classification Report:")
        print(classification_report(self.y_test, y_pred))

        # Plot confusion matrix
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Not Dropout', 'Dropout'],
                    yticklabels=['Not Dropout', 'Dropout'])
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title('Confusion Matrix - LSTM')
        plt.show()

        # Plot training history
        plt.figure(figsize=(12, 5))
        plt.subplot(1, 2, 1)
        plt.plot(history.history['accuracy'])
        plt.plot(history.history['val_accuracy'])
        plt.title('Model Accuracy')
        plt.ylabel('Accuracy')
        plt.xlabel('Epoch')
        plt.legend(['Train', 'Validation'], loc='lower right')

        plt.subplot(1, 2, 2)
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('Model Loss')
        plt.ylabel('Loss')
        plt.xlabel('Epoch')
        plt.legend(['Train', 'Validation'], loc='upper right')
        plt.tight_layout()
        plt.show()

        # Set as current model
        self.current_model = 'lstm'

    def compare_models(self):
        """Compare all trained models"""
        if not self.results:
            print("No models trained yet. Please train at least one model first.")
            return

        print("Model Comparison")
        print("---------------")

        # Create comparison table
        comparison = {
            'Model': [],
            'Accuracy': [],
            'Precision (Dropout)': [],
            'Recall (Dropout)': [],
            'F1-Score (Dropout)': [],
            'ROC AUC': [],
            'Execution Time (s)': []
        }

        # Collect results for each model
        for model_name, result in self.results.items():
            comparison['Model'].append(model_name)
            comparison['Accuracy'].append(result['report']['accuracy'])
            comparison['Precision (Dropout)'].append(result['report']['1']['precision'])
            comparison['Recall (Dropout)'].append(result['report']['1']['recall'])
            comparison['F1-Score (Dropout)'].append(result['report']['1']['f1-score'])
            comparison['ROC AUC'].append(result['roc_auc'])
            comparison['Execution Time (s)'].append(result['execution_time'])

        # Display comparison table
        comparison_df = pd.DataFrame(comparison)
        display(comparison_df)

        # Plot ROC curves for all models
        plt.figure(figsize=(10, 8))

        for model_name, result in self.results.items():
            plt.plot(result['fpr'], result['tpr'], label=f'{model_name} (AUC = {result["roc_auc"]:.4f})')

        plt.plot([0, 1], [0, 1], 'k--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('ROC Curves for all Models')
        plt.legend(loc="lower right")
        plt.show()

        # Bar chart comparing key metrics
        plt.figure(figsize=(12, 6))

        metrics = ['Accuracy', 'Precision (Dropout)', 'Recall (Dropout)', 'F1-Score (Dropout)']
        x = np.arange(len(metrics))
        width = 0.2
        multiplier = 0

        for model_name, result in self.results.items():
            offset = width * multiplier
            values = [
                result['report']['accuracy'],
                result['report']['1']['precision'],
                result['report']['1']['recall'],
                result['report']['1']['f1-score']
            ]

            plt.bar(x + offset, values, width, label=model_name)
            multiplier += 1

        plt.ylabel('Score')
        plt.title('Performance Comparison')
        plt.xticks(x + width, metrics)
        plt.legend(loc='upper left')
        plt.ylim(0, 1)
        plt.tight_layout()
        plt.show()

    def explain_predictions(self, num_samples=5):
        """Explain model predictions using SHAP values"""
        if self.current_model != 'xgboost' or 'xgboost' not in self.models:
            print("SHAP explanation is currently only available for XGBoost models.")
            print("Please train an XGBoost model first.")
            return

        print("Generating SHAP explanations for model predictions...")

        # Calculate SHAP values for the test set
        shap_values = self.explainer.shap_values(self.X_test)

        # Summary plot
        plt.figure(figsize=(10, 8))
        shap.summary_plot(shap_values, self.X_test, plot_type="bar", show=False)
        plt.title("Feature Importance Based on SHAP Values")
        plt.tight_layout()
        plt.show()

        # Detailed summary plot
        plt.figure(figsize=(12, 10))
        shap.summary_plot(shap_values, self.X_test, show=False)
        plt.title("Feature Impact on Predictions")
        plt.tight_layout()
        plt.show()

        # Individual explanations for a few samples
        print(f"\nDetailed explanations for {num_samples} sample predictions:")

        for i in range(min(num_samples, len(self.X_test))):
            plt.figure(figsize=(12, 6))

            # Get actual and predicted values
            actual = self.y_test.iloc[i]
            prediction = self.models['xgboost'].predict_proba([self.X_test.iloc[i]])[0][1]

            # Create force plot
            shap.force_plot(
                base_value=self.explainer.expected_value,
                shap_values=shap_values[i],
                features=self.X_test.iloc[i],
                feature_names=self.X_test.columns,
                matplotlib=True,
                show=False
            )

            plt.title(f"Sample {i+1}: Actual={actual}, Predicted Probability={prediction:.4f}")
            plt.tight_layout()
            plt.show()

            # Print top 5 contributing features
            feature_importance = pd.DataFrame({
                'Feature': self.X_test.columns,
                'Importance': np.abs(shap_values[i])
            }).sort_values('Importance', ascending=False).head(5)

            print(f"Top contributing features for Sample {i+1}:")
            display(feature_importance)
            print("\n" + "-"*50 + "\n")

    def predict_dropout_risk(self, student_data=None):
        """Predict dropout risk for a single student or a sample from test set"""
        if not self.models:
            print("No models trained yet. Please train at least one model first.")
            return

        if student_data is None:
            # Use a sample from the test set
            sample_idx = np.random.choice(len(self.X_test))
            student_data = self.X_test.iloc[sample_idx]
            actual_label = self.y_test.iloc[sample_idx]
            print(f"Using sample {sample_idx} from test set.")
            print(f"Actual dropout status: {'Yes' if actual_label == 1 else 'No'}")

        # Make predictions with all available models
        predictions = {}

        for model_name, model in self.models.items():
            start_time = time.time()

            if model_name == 'lstm' and hasattr(self, 'temporal_X_test'):
                # For LSTM, reshape the data
                sample_data = self.temporal_X_test[sample_idx:sample_idx+1]
                pred_prob = model.predict(sample_data)[0][0]
            else:
                # For other models
                if isinstance(student_data, pd.Series):
                    sample_data = student_data.values.reshape(1, -1)
                else:
                    sample_data = student_data.reshape(1, -1)

                pred_prob = model.predict_proba(sample_data)[0][1]

            execution_time = time.time() - start_time

            risk_level = "High" if pred_prob >= 0.7 else "Medium" if pred_prob >= 0.4 else "Low"

            predictions[model_name] = {
                'probability': pred_prob,
                'risk_level': risk_level,
                'execution_time': execution_time
            }

        # Display predictions
        print("\nDropout Risk Predictions")
        print("------------------------")

        pred_df = pd.DataFrame({
            'Model': list(predictions.keys()),
            'Dropout Probability': [pred['probability'] for pred in predictions.values()],
            'Risk Level': [pred['risk_level'] for pred in predictions.values()],
            'Execution Time (s)': [pred['execution_time'] for pred in predictions.values()]
        })

        display(pred_df)

        # Visualize predictions
        plt.figure(figsize=(10, 6))
        bars = plt.barh(pred_df['Model'], pred_df['Dropout Probability'], color=['green' if p < 0.4 else 'orange' if p < 0.7 else 'red' for p in pred_df['Dropout Probability']])

        plt.title('Dropout Risk Probability by Model')
        plt.xlabel('Probability')
        plt.xlim(0, 1)

        # Add threshold lines
        plt.axvline(x=0.4, color='orange', linestyle='--', alpha=0.7, label='Medium Risk Threshold')
        plt.axvline(x=0.7, color='red', linestyle='--', alpha=0.7, label='High Risk Threshold')

        # Add probability values on bars
        for bar, prob in zip(bars, pred_df['Dropout Probability']):
            plt.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2, f'{prob:.2f}', va='center')

        plt.legend()
        plt.tight_layout()
        plt.show()

        # If XGBoost is available and used for prediction, provide SHAP explanation
        if 'xgboost' in self.models and self.explainer is not None:
            print("\nExplanation for XGBoost prediction:")

            # Calculate SHAP values
            if isinstance(student_data, pd.Series):
                explanation = self.explainer.shap_values(student_data.values.reshape(1, -1))[0]
            else:
                explanation = self.explainer.shap_values(student_data.reshape(1, -1))[0]

            # Plot explanation
            plt.figure(figsize=(12, 6))
            shap.force_plot(
                base_value=self.explainer.expected_value,
                shap_values=explanation,
                features=student_data,
                feature_names=self.X_test.columns,
                matplotlib=True,
                show=False
            )
            plt.title('Factors Influencing Dropout Prediction')
            plt.tight_layout()
            plt.show()

            # Provide actionable insights
            feature_impact = pd.DataFrame({
                'Feature': self.X_test.columns,
                'Impact': explanation
            }).sort_values('Impact', ascending=False)

            # Top positive factors (increasing dropout risk)
            positive_factors = feature_impact[feature_impact['Impact'] > 0].head(5)

            # Top negative factors (decreasing dropout risk)
            negative_factors = feature_impact[feature_impact['Impact'] < 0].head(5)

            print("\nActionable Insights:")
            print("-------------------")

            if not positive_factors.empty:
                print("Top risk factors to address:")
                for i, (feature, impact) in enumerate(zip(positive_factors['Feature'], positive_factors['Impact']), 1):
                    print(f"{i}. {feature}: Contributes {impact:.4f} to dropout risk")

            if not negative_factors.empty:
                print("\nProtective factors to maintain:")
                for i, (feature, impact) in enumerate(zip(negative_factors['Feature'], negative_factors['Impact']), 1):
                    print(f"{i}. {feature}: Reduces dropout risk by {abs(impact):.4f}")

            print("\nRecommendations:")
            print("For high-risk students, consider:")
            print("1. Academic interventions targeting specific subjects")
            print("2. Increased advisor check-ins")
            print("3. Connecting to support services")
            print("4. Peer mentoring programs")
            print("5. Financial aid review if applicable")

# Create UI components
def create_ui():
    """Create the UI for the Student Dropout Prediction System"""
    # File upload widget
    upload_button = widgets.FileUpload(
        description='Upload Dataset',
        accept='.csv, .xlsx, .xls',
        multiple=False,
        layout=Layout(width='300px')
    )

    # Analysis options
    temporal_checkbox =    widgets.Checkbox(
        value=True,
        description='Process Temporal Data (for LSTM)',
        disabled=False
    )

    optimize_checkbox = widgets.Checkbox(
        value=True,
        description='Use Bayesian Optimization',
        disabled=False
    )

    # Target column selector
    target_input = widgets.Text(
        value='dropout',
        placeholder='dropout',
        description='Target Column:',
        disabled=False
    )

    # Button widgets
    analyze_button = widgets.Button(
        description='Analyze Data',
        disabled=False,
        button_style='info',
        tooltip='Analyze the dataset',
        icon='chart-line'
    )

    train_baseline_button = widgets.Button(
        description='Train Baseline (LR)',
        disabled=True,
        button_style='',
        tooltip='Train Logistic Regression model',
        icon='play'
    )

    train_xgboost_button = widgets.Button(
        description='Train XGBoost',
        disabled=True,
        button_style='',
        tooltip='Train XGBoost model',
        icon='play'
    )

    train_lstm_button = widgets.Button(
        description='Train LSTM',
        disabled=True,
        button_style='',
        tooltip='Train LSTM model',
        icon='play'
    )

    compare_button = widgets.Button(
        description='Compare Models',
        disabled=True,
        button_style='',
        tooltip='Compare all trained models',
        icon='balance-scale'
    )

    explain_button = widgets.Button(
        description='Explain Predictions',
        disabled=True,
        button_style='',
        tooltip='Explain model predictions using SHAP',
        icon='question-circle'
    )

    predict_button = widgets.Button(
        description='Predict Sample',
        disabled=True,
        button_style='',
        tooltip='Predict dropout risk for a sample',
        icon='user'
    )

    # Output area
    output = widgets.Output()

    # Progress indicator
    progress = widgets.IntProgress(
        value=0,
        min=0,
        max=10,
        description='Progress:',
        style={'description_width': 'initial'},
        orientation='horizontal'
    )

    # Status message
    status = widgets.HTML(value="<p>Upload a dataset to begin.</p>")

    # Arrange the widgets
    header = widgets.HTML(value="<h1>Student Dropout Prediction System</h1>")
    description = widgets.HTML(
        value="""<p>This system uses advanced machine learning techniques to predict student dropout risk:</p>
        <ul>
            <li><strong>XGBoost:</strong> Captures non-linear relationships between features</li>
            <li><strong>LSTM Networks:</strong> Processes sequential data to identify trends over time</li>
            <li><strong>SMOTE:</strong> Balances imbalanced datasets</li>
            <li><strong>SHAP:</strong> Provides explainable predictions for actionable interventions</li>
            <li><strong>Bayesian Optimization:</strong> Optimizes hyperparameters for better performance</li>
        </ul>"""
    )

    data_section = widgets.VBox([
        widgets.HTML(value="<h2>Data Input</h2>"),
        widgets.HBox([upload_button, target_input]),
        widgets.HBox([temporal_checkbox, optimize_checkbox]),
        analyze_button
    ])

    model_section = widgets.VBox([
        widgets.HTML(value="<h2>Model Training</h2>"),
        widgets.HBox([train_baseline_button, train_xgboost_button, train_lstm_button]),
        widgets.HBox([compare_button, explain_button, predict_button])
    ])

    status_section = widgets.VBox([
        progress,
        status
    ])

    # Create the main layout
    main_layout = widgets.VBox([
        header,
        description,
        data_section,
        model_section,
        status_section,
        output
    ])

        # Initialize the predictor
    predictor = StudentDropoutPredictor()

    # Define button callbacks
    def on_upload_change(change):
        with output:
            if upload_button.value:
                status.value = "<p>Dataset uploaded. Click 'Analyze Data' to proceed.</p>"
                analyze_button.disabled = False

    def on_analyze_click(b):
        with output:
            clear_output()
            status.value = "<p>Analyzing dataset...</p>"
            progress.value = 2

            if upload_button.value:
                file_info = list(upload_button.value.items())[0][1]
                if predictor.load_data(file_info):
                    status.value = "<p>Dataset loaded. Processing data...</p>"
                    progress.value = 5

                    if predictor.preprocess_data(target_col=target_input.value, temporal=temporal_checkbox.value):
                        status.value = "<p>Data processed successfully. Ready to train models.</p>"
                        progress.value = 10

                        # Enable training buttons
                        train_baseline_button.disabled = False
                        train_xgboost_button.disabled = False
                        if temporal_checkbox.value and predictor.semester_columns:
                            train_lstm_button.disabled = False
                        else:
                            train_lstm_button.disabled = True
                            status.value += "<p>Note: LSTM training disabled as no temporal data detected.</p>"
                    else:
                        status.value = "<p>Error preprocessing data.</p>"
                        progress.value = 0
                else:
                    status.value = "<p>Error loading dataset.</p>"
                    progress.value = 0
            else:
                status.value = "<p>Please upload a dataset first.</p>"
                progress.value = 0

    def on_train_baseline_click(b):
        with output:
            clear_output()
            status.value = "<p>Training Logistic Regression model...</p>"
            progress.value = 3

            predictor.train_baseline_model()

            status.value = "<p>Logistic Regression model trained successfully.</p>"
            progress.value = 10
            compare_button.disabled = False
            predict_button.disabled = False

    def on_train_xgboost_click(b):
        with output:
            clear_output()
            status.value = "<p>Training XGBoost model...</p>"
            progress.value = 3

            predictor.train_xgboost_model(optimize=optimize_checkbox.value)

            status.value = "<p>XGBoost model trained successfully.</p>"
            progress.value = 10
            compare_button.disabled = False
            predict_button.disabled = False
            explain_button.disabled = False

    def on_train_lstm_click(b):
        with output:
            clear_output()
            status.value = "<p>Training LSTM model...</p>"
            progress.value = 3

            predictor.train_lstm_model()

            status.value = "<p>LSTM model trained successfully.</p>"
            progress.value = 10
            compare_button.disabled = False
            predict_button.disabled = False

    def on_compare_click(b):
        with output:
            clear_output()
            status.value = "<p>Comparing models...</p>"
            progress.value = 5

            predictor.compare_models()

            status.value = "<p>Model comparison completed.</p>"
            progress.value = 10

    def on_explain_click(b):
        with output:
            clear_output()
            status.value = "<p>Generating model explanations...</p>"
            progress.value = 5

            predictor.explain_predictions()

            status.value = "<p>Model explanations generated.</p>"
            progress.value = 10

    def on_predict_click(b):
        with output:
            clear_output()
            status.value = "<p>Predicting dropout risk for a sample...</p>"
            progress.value = 5

            predictor.predict_dropout_risk()

            status.value = "<p>Prediction completed.</p>"
            progress.value = 10

    # Register callbacks
    upload_button.observe(on_upload_change, names='value')
    analyze_button.on_click(on_analyze_click)
    train_baseline_button.on_click(on_train_baseline_click)
    train_xgboost_button.on_click(on_train_xgboost_click)
    train_lstm_button.on_click(on_train_lstm_click)
    compare_button.on_click(on_compare_click)
    explain_button.on_click(on_explain_click)
    predict_button.on_click(on_predict_click)

    return main_layout

# Sample data generator for testing purposes
def generate_sample_data(n_samples=1000, n_semesters=4, dropout_rate=0.195):
    """Generate synthetic student data for testing the system"""
    np.random.seed(42)

    # Define the features
    student_ids = np.arange(1, n_samples + 1)
    age = np.random.normal(21, 3, n_samples).round(0).clip(18, 35)
    gender = np.random.choice(['M', 'F'], n_samples)
    scholarship = np.random.choice([0, 1], n_samples, p=[0.7, 0.3])
    work_status = np.random.choice(['None', 'Part-time', 'Full-time'], n_samples, p=[0.6, 0.3, 0.1])

    # Create initial DataFrame
    df = pd.DataFrame({
        'student_id': student_ids,
        'age': age,
        'gender': gender,
        'scholarship': scholarship,
        'work_status': work_status
    })

    # Generate semester data
    for semester in range(1, n_semesters + 1):
        # Previous semester's GPA affects current semester (for semester > 1)
        if semester == 1:
            base_gpa = np.random.normal(3.0, 0.7, n_samples).clip(0, 4.0)
        else:
            # Add some randomness but maintain correlation with previous semester
            prev_gpa = df[f'sem{semester-1}_gpa']
            base_gpa = prev_gpa + np.random.normal(0, 0.3, n_samples)
            base_gpa = base_gpa.clip(0, 4.0)

        # Work status affects attendance
        work_effect = df['work_status'].map({'None': 0, 'Part-time': -5, 'Full-time': -15})
        base_attendance = np.random.normal(90, 10, n_samples) + work_effect

        # Lower GPA in previous semester affects current attendance
        if semester > 1:
            gpa_effect = (df[f'sem{semester-1}_gpa'] < 2.5).astype(int) * -10
            base_attendance += gpa_effect

        # Clip attendance to valid range
        base_attendance = base_attendance.clip(0, 100)

        # Lower attendance affects current GPA
        attendance_effect = (base_attendance < 70).astype(int) * -0.5
        base_gpa += attendance_effect

        # Generate assignment completion rate
        base_assignments = base_attendance / 100 * 0.7 + np.random.normal(0.2, 0.1, n_samples)
        base_assignments = base_assignments.clip(0, 1)

        # Generate participation score
        base_participation = base_attendance / 100 * 0.6 + np.random.normal(0.3, 0.15, n_samples)
        base_participation = base_participation.clip(0, 1)

        # Add semester data to DataFrame
        df[f'sem{semester}_gpa'] = base_gpa.round(2)
        df[f'sem{semester}_attendance'] = base_attendance.round(1)
        df[f'sem{semester}_assignments'] = (base_assignments * 100).round(1)
        df[f'sem{semester}_participation'] = (base_participation * 100).round(1)

    # Generate target variable (dropout)
    # Factors that increase dropout probability:
    # - Low GPA in any semester
    # - Low attendance
    # - Working full-time
    # - No scholarship

    # Create a dropout risk score
    risk_score = np.zeros(n_samples)

    # Low GPA increases risk
    for semester in range(1, n_semesters + 1):
        risk_score += (df[f'sem{semester}_gpa'] < 2.0).astype(int) * 2
        risk_score += (df[f'sem{semester}_gpa'] < 2.5).astype(int) * 1

    # Declining GPA trend increases risk
    if n_semesters > 1:
        for semester in range(2, n_semesters + 1):
            risk_score += (df[f'sem{semester}_gpa'] < df[f'sem{semester-1}_gpa'] - 0.5).astype(int) * 1.5

    # Low attendance increases risk
    for semester in range(1, n_semesters + 1):
        risk_score += (df[f'sem{semester}_attendance'] < 70).astype(int) * 1.5

    # Work status affects risk
    risk_score += (df['work_status'] == 'Full-time').astype(int) * 2
    risk_score += (df['work_status'] == 'Part-time').astype(int) * 0.5

    # No scholarship increases risk
    risk_score += (df['scholarship'] == 0).astype(int) * 1

    # Normalize risk score to a probability
    risk_prob = 1 / (1 + np.exp(-(risk_score - 5) / 3))

    # Adjust to match desired dropout rate
    threshold = np.percentile(risk_prob, 100 - dropout_rate * 100)

    # Assign dropout label
    df['dropout'] = (risk_prob >= threshold).astype(int)

    print(f"Generated sample dataset with {n_samples} students and {n_semesters} semesters.")
    print(f"Dropout rate: {df['dropout'].mean() * 100:.1f}%")

    return df

# Main execution
if __name__ == "__main__":
    print("Student Dropout Prediction System")
    print("================================")
    print("This system uses advanced machine learning techniques to predict student dropout risk.")

    # Display the UI
    main_ui = create_ui()
    display(main_ui)

    # Output information about sample data
    print("\nNo dataset? You can generate a sample dataset for testing:")
    print("```python")
    print("sample_data = generate_sample_data(n_samples=1000, n_semesters=4)")
    print("sample_data.to_csv('student_data.csv', index=False)")
    print("```")

# Student Dropout Prediction System
# Advanced implementation with XGBoost, LSTM, SMOTE, SHAP and Bayesian Optimization

# Install required packages
!pip install xgboost shap imbalanced-learn scikit-optimize ipywidgets matplotlib seaborn tensorflow pandas numpy scikit-learn yellowbrick
!jupyter nbextension enable --py widgetsnbextension

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from sklearn.linear_model import LogisticRegression
import xgboost as xgb
from imblearn.over_sampling import SMOTE
import shap
from skopt import BayesSearchCV
from skopt.space import Real, Integer
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout
from tensorflow.keras.callbacks import EarlyStopping
import ipywidgets as widgets
from ipywidgets import HBox, VBox, Layout
import io
import time
import warnings
from IPython.display import display, HTML, clear_output
warnings.filterwarnings('ignore')

# Define the main class for the Student Dropout Prediction System
class StudentDropoutPredictor:
    def __init__(self):
        self.data = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.X_train_resampled = None
        self.y_train_resampled = None
        self.models = {}
        self.results = {}
        self.temporal_features = []
        self.scaler = StandardScaler()
        self.le = LabelEncoder()
        self.explainer = None
        self.semester_columns = []
        self.lstm_model = None
        self.current_model = None

    def load_data(self, file):
        """Load the dataset from uploaded file"""
        try:
            # Check if any file is uploaded
            if file:
                # Extract the first file from the uploaded files
                uploaded_file = list(file.values())[0]  # Get the first uploaded file
                file_content = uploaded_file['content']  # Get the content
                file_name = uploaded_file['name']  # Get the name

                # Load the data based on the file extension
                if file_name.endswith('.csv'):
                    self.data = pd.read_csv(io.BytesIO(file_content))
                elif file_name.endswith(('.xls', '.xlsx')):
                    self.data = pd.read_excel(io.BytesIO(file_content))
                else:
                    raise ValueError("Unsupported file format. Please upload a CSV or Excel file.")

                # Display data info
                print(f"Dataset loaded successfully. Shape: {self.data.shape}")
                print("\nData Sample:")
                display(self.data.head())
                print("\nData Info:")
                self.data.info()
                print("\nSummary Statistics:")
                display(self.data.describe())
                print("\nMissing Values:")
                display(self.data.isnull().sum())

                # Check for class imbalance
                if 'dropout' in self.data.columns:
                    target_col = 'dropout'
                elif 'Target' in self.data.columns:  # Adjusted to match your dataset
                    target_col = 'Target'
                else:
                    print("Warning: Could not identify target column. Please rename your target column to 'dropout' or 'Target'.")
                    return

                # Class distribution
                class_counts = self.data[target_col].value_counts()
                dropout_rate = class_counts[1] / len(self.data) * 100 if 1 in class_counts.index else 0
                print(f"\nClass Distribution:\n{class_counts}")
                print(f"Dropout Rate: {dropout_rate:.2f}%")

                # Visualize class distribution
                plt.figure(figsize=(8, 6))
                sns.countplot(x=target_col, data=self.data)
                plt.title('Class Distribution')
                plt.ylabel('Count')
                plt.xlabel('Dropout (1 = Yes, 0 = No)')
                plt.show()

                return True
            else:
                print("No file uploaded.")
                return False
        except Exception as e:
            print(f"Error loading data: {str(e)}")
            return False

    def preprocess_data(self, test_size=0.2, random_state=42, target_col='dropout', temporal=True):
        """Preprocess the data for model training"""
        try:
            # If target column is not 'dropout', check for alternatives
            if target_col not in self.data.columns:
                if 'Target' in self.data.columns:
                    target_col = 'Target'
                else:
                    print("Warning: Target column not found. Please specify the correct target column name.")
                    return False

            # Identify temporal features (semester-wise features)
            if temporal:
                self.semester_columns = []
                # Try to automatically identify semester columns (assuming they follow patterns like 'sem1_', 'semester1_', etc.)
                for col in self.data.columns:
                    if col.startswith(('sem', 'semester', 'term')) and '_' in col:
                        prefix = col.split('_')[0]
                        self.semester_columns.append(prefix)

                self.semester_columns = list(set(self.semester_columns))

                if not self.semester_columns:
                    print("No semester columns detected. Treating data as non-temporal.")
                else:
                    print(f"Detected semester columns: {self.semester_columns}")

            # Separate features and target
            X = self.data.drop(columns=[target_col])
            y = self.data[target_col]

            # Handle categorical variables
            categorical_cols = X.select_dtypes(include=['object', 'category']).columns
            for col in categorical_cols:
                X[col] = self.le.fit_transform(X[col])

            # Split the data
            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
                X, y, test_size=test_size, random_state=random_state, stratify=y
            )

            # Scale the features
            self.X_train = pd.DataFrame(
                self.scaler.fit_transform(self.X_train),
                columns=X.columns
            )
            self.X_test = pd.DataFrame(
                self.scaler.transform(self.X_test),
                columns=X.columns
            )

            # Apply SMOTE to handle class imbalance
            smote = SMOTE(random_state=random_state)
            self.X_train_resampled, self.y_train_resampled = smote.fit_resample(self.X_train, self.y_train)

            print("Data preprocessing completed successfully.")
            print(f"Original training set shape: {self.X_train.shape}, Class distribution: {pd.Series(self.y_train).value_counts()}")
            print(f"Resampled training set shape: {self.X_train_resampled.shape}, Class distribution: {pd.Series(self.y_train_resampled).value_counts()}")

            # Reshape data for LSTM if temporal features are present
            if self.semester_columns:
                print("Preparing temporal data for LSTM...")
                self.prepare_temporal_data()

            return True
        except Exception as e:
            print(f"Error preprocessing data: {str(e)}")
            return False

    def prepare_temporal_data(self):
        """Prepare temporal data for LSTM model"""
        self.temporal_features = []
        self.temporal_X_train = []
        self.temporal_X_test = []

        # Extract and organize features by semester
        # This is a simplified approach - you may need to adjust based on your actual data structure
        for col in self.X_train.columns:
            for sem in self.semester_columns:
                if col.startswith(sem + '_'):
                    self.temporal_features.append(col)

        # If temporal features were found, reshape for LSTM
        if self.temporal_features:
            num_semesters = len(self.semester_columns)
            num_features_per_semester = len(self.temporal_features) // num_semesters

            # Reshape data: (samples, time steps, features)
            self.temporal_X_train = np.zeros((len(self.X_train_resampled), num_semesters, num_features_per_semester))
            self.temporal_X_test = np.zeros((len(self.X_test), num_semesters, num_features_per_semester))

            for i, sem in enumerate(self.semester_columns):
                sem_features = [f for f in self.temporal_features if f.startswith(sem + '_')]
                if sem_features:
                    self.temporal_X_train[:, i, :] = self.X_train_resampled[sem_features].values
                    self.temporal_X_test[:, i, :] = self.X_test[sem_features].values

            print(f"Temporal data prepared. Shape: {self.temporal_X_train.shape} (samples, semesters, features per semester)")
        else:
            print("No temporal features found. LSTM model will not be used.")

    def train_baseline_model(self):
        """Train the baseline Logistic Regression model"""
        start_time = time.time()
        print("Training Logistic Regression baseline model...")

        # Create and train the model
        lr_model = LogisticRegression(max_iter=1000, random_state=42)
        lr_model.fit(self.X_train, self.y_train)

        # Make predictions
        y_pred = lr_model.predict(self.X_test)

        # Evaluate the model
        report = classification_report(self.y_test, y_pred, output_dict=True)
        cm = confusion_matrix(self.y_test, y_pred)

        # Calculate ROC curve
        y_pred_proba = lr_model.predict_proba(self.X_test)[:, 1]
        fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)

        execution_time = time.time() - start_time

        # Store results
        self.models['logistic_regression'] = lr_model
        self.results['logistic_regression'] = {
            'report': report,
            'confusion_matrix': cm,
            'execution_time': execution_time,
            'roc_auc': roc_auc,
            'fpr': fpr,
            'tpr': tpr
        }

        print(f"Baseline Logistic Regression model trained in {execution_time:.3f} seconds")
        print(f"Test set accuracy: {report['accuracy']:.4f}")
        print(f"ROC AUC: {roc_auc:.4f}")
        print("Classification Report:")
        print(classification_report(self.y_test, y_pred))

        # Plot confusion matrix
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Not Dropout', 'Dropout'],
                    yticklabels=['Not Dropout', 'Dropout'])
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title('Confusion Matrix - Logistic Regression')
        plt.show()

    def train_xgboost_model(self, optimize=True):
        """Train the XGBoost model with optional Bayesian optimization"""
        start_time = time.time()
        print("Training XGBoost model...")

        if optimize:
            print("Using Bayesian optimization to find optimal hyperparameters...")

            # Define the search space
            search_spaces = {
                'learning_rate': Real(0.01, 0.3),
                'max_depth': Integer(3, 10),
                'min_child_weight': Integer(1, 10),
                'gamma': Real(0, 1),
                'subsample': Real(0.5, 1.0),
                'colsample_bytree': Real(0.5, 1.0),
                'n_estimators': Integer(50, 300)
            }

            # Create the XGBoost model
            xgb_model = xgb.XGBClassifier(
                objective='binary:logistic',
                random_state=42,
                use_label_encoder=False,
                eval_metric='logloss'
            )

            # Perform Bayesian optimization
            bayes_search = BayesSearchCV(
                xgb_model,
                search_spaces,
                n_iter=10,  # Reduced for faster execution in Colab
                cv=3,        # Reduced for faster execution
                n_jobs=-1,
                random_state=42,
                scoring='roc_auc'
            )

            bayes_search.fit(self.X_train_resampled, self.y_train_resampled)

            # Get the best model
            xgb_model = bayes_search.best_estimator_
            print(f"Best hyperparameters: {bayes_search.best_params_}")
        else:
            # Use default hyperparameters
            xgb_model = xgb.XGBClassifier(
                objective='binary:logistic',
                random_state=42,
                use_label_encoder=False,
                eval_metric='logloss'
            )
            xgb_model.fit(self.X_train_resampled, self.y_train_resampled)

        # Make predictions
        y_pred = xgb_model.predict(self.X_test)

        # Evaluate the model
        report = classification_report(self.y_test, y_pred, output_dict=True)
        cm = confusion_matrix(self.y_test, y_pred)

        # Calculate ROC curve
        y_pred_proba = xgb_model.predict_proba(self.X_test)[:, 1]
        fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)

        execution_time = time.time() - start_time

        # Store results
        self.models['xgboost'] = xgb_model
        self.results['xgboost'] = {
            'report': report,
            'confusion_matrix': cm,
            'execution_time': execution_time,
            'roc_auc': roc_auc,
            'fpr': fpr,
            'tpr': tpr
        }

        # Create SHAP explainer
        self.explainer = shap.TreeExplainer(xgb_model)

        print(f"XGBoost model trained in {execution_time:.3f} seconds")
        print(f"Test set accuracy: {report['accuracy']:.4f}")
        print(f"ROC AUC: {roc_auc:.4f}")
        print("Classification Report:")
        print(classification_report(self.y_test, y_pred))

        # Plot confusion matrix
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Not Dropout', 'Dropout'],
                    yticklabels=['Not Dropout', 'Dropout'])
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title('Confusion Matrix - XGBoost')
        plt.show()

        # Set as current model
        self.current_model = 'xgboost'

    def train_lstm_model(self):
        """Train the LSTM model for temporal data"""
        if not hasattr(self, 'temporal_X_train') or self.temporal_X_train is None or len(self.temporal_X_train) == 0:
            print("No temporal data available for LSTM. Run preprocess_data with temporal=True first.")
            return

        start_time = time.time()
        print("Training LSTM model...")

        # Define the LSTM model architecture
        self.lstm_model = Sequential([
            LSTM(64, input_shape=(self.temporal_X_train.shape[1], self.temporal_X_train.shape[2]), return_sequences=True),
            Dropout(0.2),
            LSTM(32),
            Dropout(0.2),
            Dense(16, activation='relu'),
            Dense(1, activation='sigmoid')
        ])

        # Compile the model
        self.lstm_model.compile(
            optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy']
        )

        # Early stopping to prevent overfitting
        early_stopping = EarlyStopping(
            monitor='val_loss',
            patience=5,
            restore_best_weights=True
        )

        # Train the model
        history = self.lstm_model.fit(
            self.temporal_X_train, self.y_train_resampled,
            epochs=20,
            batch_size=32,
            validation_split=0.2,
            callbacks=[early_stopping],
            verbose=1
        )

        # Make predictions
        y_pred_proba = self.lstm_model.predict(self.temporal_X_test)
        y_pred = (y_pred_proba > 0.5).astype(int).flatten()

        # Evaluate the model
        report = classification_report(self.y_test, y_pred, output_dict=True)
        cm = confusion_matrix(self.y_test, y_pred)

        # Calculate ROC curve
        fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)

        execution_time = time.time() - start_time

        # Store results
        self.models['lstm'] = self.lstm_model
        self.results['lstm'] = {
            'report': report,
            'confusion_matrix': cm,
            'execution_time': execution_time,
            'roc_auc': roc_auc,
            'fpr': fpr,
            'tpr': tpr,
            'history': history.history
        }

        print(f"LSTM model trained in {execution_time:.3f} seconds")
        print(f"Test set accuracy: {report['accuracy']:.4f}")
        print(f"ROC AUC: {roc_auc:.4f}")
        print("Classification Report:")
        print(classification_report(self.y_test, y_pred))

        # Plot confusion matrix
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Not Dropout', 'Dropout'],
                    yticklabels=['Not Dropout', 'Dropout'])
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title('Confusion Matrix - LSTM')
        plt.show()

        # Plot training history
        plt.figure(figsize=(12, 5))
        plt.subplot(1, 2, 1)
        plt.plot(history.history['accuracy'])
        plt.plot(history.history['val_accuracy'])
        plt.title('Model Accuracy')
        plt.ylabel('Accuracy')
        plt.xlabel('Epoch')
        plt.legend(['Train', 'Validation'], loc='lower right')

        plt.subplot(1, 2, 2)
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('Model Loss')
        plt.ylabel('Loss')
        plt.xlabel('Epoch')
        plt.legend(['Train', 'Validation'], loc='upper right')
        plt.tight_layout()
        plt.show()

        # Set as current model
        self.current_model = 'lstm'

    def compare_models(self):
        """Compare all trained models"""
        if not self.results:
            print("No models trained yet. Please train at least one model first.")
            return

        print("Model Comparison")
        print("---------------")

        # Create comparison table
        comparison = {
            'Model': [],
            'Accuracy': [],
            'Precision (Dropout)': [],
            'Recall (Dropout)': [],
            'F1-Score (Dropout)': [],
            'ROC AUC': [],
            'Execution Time (s)': []
        }

        # Collect results for each model
        for model_name, result in self.results.items():
            comparison['Model'].append(model_name)
            comparison['Accuracy'].append(result['report']['accuracy'])
            comparison['Precision (Dropout)'].append(result['report']['1']['precision'])
            comparison['Recall (Dropout)'].append(result['report']['1']['recall'])
            comparison['F1-Score (Dropout)'].append(result['report']['1']['f1-score'])
            comparison['ROC AUC'].append(result['roc_auc'])
            comparison['Execution Time (s)'].append(result['execution_time'])

        # Display comparison table
        comparison_df = pd.DataFrame(comparison)
        display(comparison_df)

        # Plot ROC curves for all models
        plt.figure(figsize=(10, 8))

        for model_name, result in self.results.items():
            plt.plot(result['fpr'], result['tpr'], label=f'{model_name} (AUC = {result["roc_auc"]:.4f})')

        plt.plot([0, 1], [0, 1], 'k--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('ROC Curves for all Models')
        plt.legend(loc="lower right")
        plt.show()

        # Bar chart comparing key metrics
        plt.figure(figsize=(12, 6))

        metrics = ['Accuracy', 'Precision (Dropout)', 'Recall (Dropout)', 'F1-Score (Dropout)']
        x = np.arange(len(metrics))
        width = 0.2
        multiplier = 0

        for model_name, result in self.results.items():
            offset = width * multiplier
            values = [
                result['report']['accuracy'],
                result['report']['1']['precision'],
                result['report']['1']['recall'],
                result['report']['1']['f1-score']
            ]

            plt.bar(x + offset, values, width, label=model_name)
            multiplier += 1

        plt.ylabel('Score')
        plt.title('Performance Comparison')
        plt.xticks(x + width, metrics)
        plt.legend(loc='upper left')
        plt.ylim(0, 1)
        plt.tight_layout()
        plt.show()

    def explain_predictions(self, num_samples=5):
        """Explain model predictions using SHAP values"""
        if self.current_model != 'xgboost' or 'xgboost' not in self.models:
            print("SHAP explanation is currently only available for XGBoost models.")
            print("Please train an XGBoost model first.")
            return

        print("Generating SHAP explanations for model predictions...")

        # Calculate SHAP values for the test set
        shap_values = self.explainer.shap_values(self.X_test)

        # Summary plot
        plt.figure(figsize=(10, 8))
        shap.summary_plot(shap_values, self.X_test, plot_type="bar", show=False)
        plt.title("Feature Importance Based on SHAP Values")
        plt.tight_layout()
        plt.show()

        # Detailed summary plot
        plt.figure(figsize=(12, 10))
        shap.summary_plot(shap_values, self.X_test, show=False)
        plt.title("Feature Impact on Predictions")
        plt.tight_layout()
        plt.show()

        # Individual explanations for a few samples
        print(f"\nDetailed explanations for {num_samples} sample predictions:")

        for i in range(min(num_samples, len(self.X_test))):
            plt.figure(figsize=(12, 6))

            # Get actual and predicted values
            actual = self.y_test.iloc[i]
            prediction = self.models['xgboost'].predict_proba([self.X_test.iloc[i]])[0][1]

            # Create force plot
            shap.force_plot(
                base_value=self.explainer.expected_value,
                shap_values=shap_values[i],
                features=self.X_test.iloc[i],
                feature_names=self.X_test.columns,
                matplotlib=True,
                show=False
            )

            plt.title(f"Sample {i+1}: Actual={actual}, Predicted Probability={prediction:.4f}")
            plt.tight_layout()
            plt.show()

            # Print top 5 contributing features
            feature_importance = pd.DataFrame({
                'Feature': self.X_test.columns,
                'Importance': np.abs(shap_values[i])
            }).sort_values('Importance', ascending=False).head(5)

            print(f"Top contributing features for Sample {i+1}:")
            display(feature_importance)
            print("\n" + "-"*50 + "\n")

    def predict_dropout_risk(self, student_data=None):
        """Predict dropout risk for a single student or a sample from test set"""
        if not self.models:
            print("No models trained yet. Please train at least one model first.")
            return

        if student_data is None:
            # Use a sample from the test set
            sample_idx = np.random.choice(len(self.X_test))
            student_data = self.X_test.iloc[sample_idx]
            actual_label = self.y_test.iloc[sample_idx]
            print(f"Using sample {sample_idx} from test set.")
            print(f"Actual dropout status: {'Yes' if actual_label == 1 else 'No'}")

        # Make predictions with all available models
        predictions = {}

        for model_name, model in self.models.items():
            start_time = time.time()

            if model_name == 'lstm' and hasattr(self, 'temporal_X_test'):
                # For LSTM, reshape the data
                sample_data = self.temporal_X_test[sample_idx:sample_idx+1]
                pred_prob = model.predict(sample_data)[0][0]
            else:
                # For other models
                if isinstance(student_data, pd.Series):
                    sample_data = student_data.values.reshape(1, -1)
                else:
                    sample_data = student_data.reshape(1, -1)

                pred_prob = model.predict_proba(sample_data)[0][1]

            execution_time = time.time() - start_time

            risk_level = "High" if pred_prob >= 0.7 else "Medium" if pred_prob >= 0.4 else "Low"

            predictions[model_name] = {
                'probability': pred_prob,
                'risk_level': risk_level,
                'execution_time': execution_time
            }

        # Display predictions
        print("\nDropout Risk Predictions")
        print("------------------------")

        pred_df = pd.DataFrame({
            'Model': list(predictions.keys()),
            'Dropout Probability': [pred['probability'] for pred in predictions.values()],
            'Risk Level': [pred['risk_level'] for pred in predictions.values()],
            'Execution Time (s)': [pred['execution_time'] for pred in predictions.values()]
        })

        display(pred_df)

        # Visualize predictions
        plt.figure(figsize=(10, 6))
        bars = plt.barh(pred_df['Model'], pred_df['Dropout Probability'], color=['green' if p < 0.4 else 'orange' if p < 0.7 else 'red' for p in pred_df['Dropout Probability']])

        plt.title('Dropout Risk Probability by Model')
        plt.xlabel('Probability')
        plt.xlim(0, 1)

        # Add threshold lines
        plt.axvline(x=0.4, color='orange', linestyle='--', alpha=0.7, label='Medium Risk Threshold')
        plt.axvline(x=0.7, color='red', linestyle='--', alpha=0.7, label='High Risk Threshold')

        # Add probability values on bars
        for bar, prob in zip(bars, pred_df['Dropout Probability']):
            plt.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2, f'{prob:.2f}', va='center')

        plt.legend()
        plt.tight_layout()
        plt.show()

        # If XGBoost is available and used for prediction, provide SHAP explanation
        if 'xgboost' in self.models and self.explainer is not None:
            print("\nExplanation for XGBoost prediction:")

            # Calculate SHAP values
            if isinstance(student_data, pd.Series):
                explanation = self.explainer.shap_values(student_data.values.reshape(1, -1))[0]
            else:
                explanation = self.explainer.shap_values(student_data.reshape(1, -1))[0]

            # Plot explanation
            plt.figure(figsize=(12, 6))
            shap.force_plot(
                base_value=self.explainer.expected_value,
                shap_values=explanation,
                features=student_data,
                feature_names=self.X_test.columns,
                matplotlib=True,
                show=False
            )
            plt.title('Factors Influencing Dropout Prediction')
            plt.tight_layout()
            plt.show()

            # Provide actionable insights
            feature_impact = pd.DataFrame({
                'Feature': self.X_test.columns,
                'Impact': explanation
            }).sort_values('Impact', ascending=False)

            # Top positive factors (increasing dropout risk)
            positive_factors = feature_impact[feature_impact['Impact'] > 0].head(5)

            # Top negative factors (decreasing dropout risk)
            negative_factors = feature_impact[feature_impact['Impact'] < 0].head(5)

            print("\nActionable Insights:")
            print("-------------------")

            if not positive_factors.empty:
                print("Top risk factors to address:")
                for i, (feature, impact) in enumerate(zip(positive_factors['Feature'], positive_factors['Impact']), 1):
                    print(f"{i}. {feature}: Contributes {impact:.4f} to dropout risk")

            if not negative_factors.empty:
                print("\nProtective factors to maintain:")
                for i, (feature, impact) in enumerate(zip(negative_factors['Feature'], negative_factors['Impact']), 1):
                    print(f"{i}. {feature}: Reduces dropout risk by {abs(impact):.4f}")

            print("\nRecommendations:")
            print("For high-risk students, consider:")
            print("1. Academic interventions targeting specific subjects")
            print("2. Increased advisor check-ins")
            print("3. Connecting to support services")
            print("4. Peer mentoring programs")
            print("5. Financial aid review if applicable")

# Create UI components
def create_ui():
    """Create the UI for the Student Dropout Prediction System"""
    # File upload widget
    upload_button = widgets.FileUpload(
        description='Upload Dataset',
        accept='.csv, .xlsx, .xls',
        multiple=False,
        layout=Layout(width='300px')
    )

    # Analysis options
    temporal_checkbox =    widgets.Checkbox(
        value=True,
        description='Process Temporal Data (for LSTM)',
        disabled=False
    )

    optimize_checkbox = widgets.Checkbox(
        value=True,
        description='Use Bayesian Optimization',
        disabled=False
    )

    # Target column selector
    target_input = widgets.Text(
        value='dropout',
        placeholder='dropout',
        description='Target Column:',
        disabled=False
    )

    # Button widgets
    analyze_button = widgets.Button(
        description='Analyze Data',
        disabled=False,
        button_style='info',
        tooltip='Analyze the dataset',
        icon='chart-line'
    )

    train_baseline_button = widgets.Button(
        description='Train Baseline (LR)',
        disabled=True,
        button_style='',
        tooltip='Train Logistic Regression model',
        icon='play'
    )

    train_xgboost_button = widgets.Button(
        description='Train XGBoost',
        disabled=True,
        button_style='',
        tooltip='Train XGBoost model',
        icon='play'
    )

    train_lstm_button = widgets.Button(
        description='Train LSTM',
        disabled=True,
        button_style='',
        tooltip='Train LSTM model',
        icon='play'
    )

    compare_button = widgets.Button(
        description='Compare Models',
        disabled=True,
        button_style='',
        tooltip='Compare all trained models',
        icon='balance-scale'
    )

    explain_button = widgets.Button(
        description='Explain Predictions',
        disabled=True,
        button_style='',
        tooltip='Explain model predictions using SHAP',
        icon='question-circle'
    )

    predict_button = widgets.Button(
        description='Predict Sample',
        disabled=True,
        button_style='',
        tooltip='Predict dropout risk for a sample',
        icon='user'
    )

    # Output area
    output = widgets.Output()

    # Progress indicator
    progress = widgets.IntProgress(
        value=0,
        min=0,
        max=10,
        description='Progress:',
        style={'description_width': 'initial'},
        orientation='horizontal'
    )

    # Status message
    status = widgets.HTML(value="<p>Upload a dataset to begin.</p>")

    # Arrange the widgets
    header = widgets.HTML(value="<h1>Student Dropout Prediction System</h1>")
    description = widgets.HTML(
        value="""<p>This system uses advanced machine learning techniques to predict student dropout risk:</p>
        <ul>
            <li><strong>XGBoost:</strong> Captures non-linear relationships between features</li>
            <li><strong>LSTM Networks:</strong> Processes sequential data to identify trends over time</li>
            <li><strong>SMOTE:</strong> Balances imbalanced datasets</li>
            <li><strong>SHAP:</strong> Provides explainable predictions for actionable interventions</li>
            <li><strong>Bayesian Optimization:</strong> Optimizes hyperparameters for better performance</li>
        </ul>"""
    )

    data_section = widgets.VBox([
        widgets.HTML(value="<h2>Data Input</h2>"),
        widgets.HBox([upload_button, target_input]),
        widgets.HBox([temporal_checkbox, optimize_checkbox]),
        analyze_button
    ])

    model_section = widgets.VBox([
        widgets.HTML(value="<h2>Model Training</h2>"),
        widgets.HBox([train_baseline_button, train_xgboost_button, train_lstm_button]),
        widgets.HBox([compare_button, explain_button, predict_button])
    ])

    status_section = widgets.VBox([
        progress,
        status
    ])

    # Create the main layout
    main_layout = widgets.VBox([
        header,
        description,
        data_section,
        model_section,
        status_section,
        output
    ])

    # Initialize the predictor
    predictor = StudentDropoutPredictor()

    # Define button callbacks
    def on_upload_change(change):
        with output:
            if upload_button.value:
                status.value = "<p>Dataset uploaded. Click 'Analyze Data' to proceed.</p>"
                analyze_button.disabled = False

    def on_analyze_click(b):
        with output:
            clear_output()
            status.value = "<p>Analyzing dataset...</p>"
            progress.value = 2

            if upload_button.value:
                file_info = list(upload_button.value.items())[0][1]
                if predictor.load_data(file_info):
                    status.value = "<p>Dataset loaded. Processing data...</p>"
                    progress.value = 5

                    if predictor.preprocess_data(target_col=target_input.value, temporal=temporal_checkbox.value):
                        status.value = "<p>Data processed successfully. Ready to train models.</p>"
                        progress.value = 10

                        # Enable training buttons
                        train_baseline_button.disabled = False
                        train_xgboost_button.disabled = False
                        if temporal_checkbox.value and predictor.semester_columns:
                            train_lstm_button.disabled = False
                        else:
                            train_lstm_button.disabled = True
                            status.value += "<p>Note: LSTM training disabled as no temporal data detected.</p>"
                    else:
                        status.value = "<p>Error preprocessing data.</p>"
                        progress.value = 0
                else:
                    status.value = "<p>Error loading dataset.</p>"
                    progress.value = 0
            else:
                status.value = "<p>Please upload a dataset first.</p>"
                progress.value = 0

    def on_train_baseline_click(b):
        with output:
            clear_output()
            status.value = "<p>Training Logistic Regression model...</p>"
            progress.value = 3

            predictor.train_baseline_model()

            status.value = "<p>Logistic Regression model trained successfully.</p>"
            progress.value = 10
            compare_button.disabled = False
            predict_button.disabled = False

    def on_train_xgboost_click(b):
        with output:
            clear_output()
            status.value = "<p>Training XGBoost model...</p>"
            progress.value = 3

            predictor.train_xgboost_model(optimize=optimize_checkbox.value)

            status.value = "<p>XGBoost model trained successfully.</p>"
            progress.value = 10
            compare_button.disabled = False
            predict_button.disabled = False
            explain_button.disabled = False

    def on_train_lstm_click(b):
        with output:
            clear_output()
            status.value = "<p>Training LSTM model...</p>"
            progress.value = 3

            predictor.train_lstm_model()

            status.value = "<p>LSTM model trained successfully.</p>"
            progress.value = 10
            compare_button.disabled = False
            predict_button.disabled = False

    def on_compare_click(b):
        with output:
            clear_output()
            status.value = "<p>Comparing models...</p>"
            progress.value = 5

            predictor.compare_models()

            status.value = "<p>Model comparison completed.</p>"
            progress.value = 10

    def on_explain_click(b):
        with output:
            clear_output()
            status.value = "<p>Generating model explanations...</p>"
            progress.value = 5

            predictor.explain_predictions()

            status.value = "<p>Model explanations generated.</p>"
            progress.value = 10

    def on_predict_click(b):
        with output:
            clear_output()
            status.value = "<p>Predicting dropout risk for a sample...</p>"
            progress.value = 5

            predictor.predict_dropout_risk()

            status.value = "<p>Prediction completed.</p>"
            progress.value = 10

    # Register callbacks
    upload_button.observe(on_upload_change, names='value')
    analyze_button.on_click(on_analyze_click)
    train_baseline_button.on_click(on_train_baseline_click)
    train_xgboost_button.on_click(on_train_xgboost_click)
    train_lstm_button.on_click(on_train_lstm_click)
    compare_button.on_click(on_compare_click)
    explain_button.on_click(on_explain_click)
    predict_button.on_click(on_predict_click)

    return main_layout

# Sample data generator for testing purposes
def generate_sample_data(n_samples=1000, n_semesters=4, dropout_rate=0.195):
    """Generate synthetic student data for testing the system"""
    np.random.seed(42)

    # Define the features
    student_ids = np.arange(1, n_samples + 1)
    age = np.random.normal(21, 3, n_samples).round(0).clip(18, 35)
    gender = np.random.choice(['M', 'F'], n_samples)
    scholarship = np.random.choice([0, 1], n_samples, p=[0.7, 0.3])
    work_status = np.random.choice(['None', 'Part-time', 'Full-time'], n_samples, p=[0.6, 0.3, 0.1])

    # Create initial DataFrame
    df = pd.DataFrame({
        'student_id': student_ids,
        'age': age,
        'gender': gender,
        'scholarship': scholarship,
        'work_status': work_status
    })

    # Generate semester data
    for semester in range(1, n_semesters + 1):
        # Previous semester's GPA affects current semester (for semester > 1)
        if semester == 1:
            base_gpa = np.random.normal(3.0, 0.7, n_samples).clip(0, 4.0)
        else:
            # Add some randomness but maintain correlation with previous semester
            prev_gpa = df[f'sem{semester-1}_gpa']
            base_gpa = prev_gpa + np.random.normal(0, 0.3, n_samples)
            base_gpa = base_gpa.clip(0, 4.0)

        # Work status affects attendance
        work_effect = df['work_status'].map({'None': 0, 'Part-time': -5, 'Full-time': -15})
        base_attendance = np.random.normal(90, 10, n_samples) + work_effect

        # Lower GPA in previous semester affects current attendance
        if semester > 1:
            gpa_effect = (df[f'sem{semester-1}_gpa'] < 2.5).astype(int) * -10
            base_attendance += gpa_effect

        # Clip attendance to valid range
        base_attendance = base_attendance.clip(0, 100)

        # Lower attendance affects current GPA
        attendance_effect = (base_attendance < 70).astype(int) * -0.5
        base_gpa += attendance_effect

        # Generate assignment completion rate
        base_assignments = base_attendance / 100 * 0.7 + np.random.normal(0.2, 0.1, n_samples)
        base_assignments = base_assignments.clip(0, 1)

        # Generate participation score
        base_participation = base_attendance / 100 * 0.6 + np.random.normal(0.3, 0.15, n_samples)
        base_participation = base_participation.clip(0, 1)

        # Add semester data to DataFrame
        df[f'sem{semester}_gpa'] = base_gpa.round(2)
        df[f'sem{semester}_attendance'] = base_attendance.round(1)
        df[f'sem{semester}_assignments'] = (base_assignments * 100).round(1)
        df[f'sem{semester}_participation'] = (base_participation * 100).round(1)

    # Generate target variable (dropout)
    # Factors that increase dropout probability:
    # - Low GPA in any semester
    # - Low attendance
    # - Working full-time
    # - No scholarship

    # Create a dropout risk score
    risk_score = np.zeros(n_samples)

    # Low GPA increases risk
    for semester in range(1, n_semesters + 1):
        risk_score += (df[f'sem{semester}_gpa'] < 2.0).astype(int) * 2
        risk_score += (df[f'sem{semester}_gpa'] < 2.5).astype(int) * 1

    # Declining GPA trend increases risk
    if n_semesters > 1:
        for semester in range(2, n_semesters + 1):
            risk_score += (df[f'sem{semester}_gpa'] < df[f'sem{semester-1}_gpa'] - 0.5).astype(int) * 1.5

    # Low attendance increases risk
    for semester in range(1, n_semesters + 1):
        risk_score += (df[f'sem{semester}_attendance'] < 70).astype(int) * 1.5

    # Work status affects risk
    risk_score += (df['work_status'] == 'Full-time').astype(int) * 2
    risk_score += (df['work_status'] == 'Part-time').astype(int) * 0.5

    # No scholarship increases risk
    risk_score += (df['scholarship'] == 0).astype(int) * 1

    # Normalize risk score to a probability
    risk_prob = 1 / (1 + np.exp(-(risk_score - 5) / 3))

    # Adjust to match desired dropout rate
    threshold = np.percentile(risk_prob, 100 - dropout_rate * 100)

    # Assign dropout label
    df['dropout'] = (risk_prob >= threshold).astype(int)

    print(f"Generated sample dataset with {n_samples} students and {n_semesters} semesters.")
    print(f"Dropout rate: {df['dropout'].mean() * 100:.1f}%")

    return df

# Main execution
if __name__ == "__main__":
    print("Student Dropout Prediction System")
    print("================================")
    print("This system uses advanced machine learning techniques to predict student dropout risk.")

    # Display the UI
    main_ui = create_ui()
    display(main_ui)

    # Output information about sample data
    print("\nNo dataset? You can generate a sample dataset for testing:")
    print("```python")
    print("sample_data = generate_sample_data(n_samples=1000, n_semesters=4)")
    print("sample_data.to_csv('student_data.csv', index=False)")
    print("```")

# Student Dropout Prediction System
# Advanced implementation with XGBoost, LSTM, SMOTE, SHAP and Bayesian Optimization

# Install required packages
!pip install xgboost shap imbalanced-learn scikit-optimize ipywidgets matplotlib seaborn tensorflow pandas numpy scikit-learn yellowbrick
!jupyter nbextension enable --py widgetsnbextension

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from sklearn.linear_model import LogisticRegression
import xgboost as xgb
from imblearn.over_sampling import SMOTE
import shap
from skopt import BayesSearchCV
from skopt.space import Real, Integer
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout
from tensorflow.keras.callbacks import EarlyStopping
import ipywidgets as widgets
from ipywidgets import HBox, VBox, Layout
import io
import time
import warnings
from IPython.display import display, HTML, clear_output
warnings.filterwarnings('ignore')

# Define the main class for the Student Dropout Prediction System
class StudentDropoutPredictor:
    def __init__(self):
        self.data = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.X_train_resampled = None
        self.y_train_resampled = None
        self.models = {}
        self.results = {}
        self.temporal_features = []
        self.scaler = StandardScaler()
        self.le = LabelEncoder()
        self.explainer = None
        self.semester_columns = []
        self.lstm_model = None
        self.current_model = None

    def load_data(self, file):
        """Load the dataset from uploaded file"""
        try:
            # Check if any file is uploaded
            if file:
                # Extract the first file from the uploaded files
                uploaded_file = list(file.values())[0]  # Get the first uploaded file
                file_content = uploaded_file['content']  # Get the content
                file_name = uploaded_file['name']  # Get the name

                # Load the data based on the file extension
                if file_name.endswith('.csv'):
                    self.data = pd.read_csv(io.BytesIO(file_content))
                elif file_name.endswith(('.xls', '.xlsx')):
                    self.data = pd.read_excel(io.BytesIO(file_content))
                else:
                    raise ValueError("Unsupported file format. Please upload a CSV or Excel file.")

                # Display data info
                print(f"Dataset loaded successfully. Shape: {self.data.shape}")
                print("\nData Sample:")
                display(self.data.head())
                print("\nData Info:")
                self.data.info()
                print("\nSummary Statistics:")
                display(self.data.describe())
                print("\nMissing Values:")
                display(self.data.isnull().sum())

                # Check for class imbalance
                if 'Target' in self.data.columns:  # Adjusted to match your dataset
                    target_col = 'Target'
                else:
                    print("Warning: Could not identify target column. Please rename your target column to 'Target'.")
                    return

                # Class distribution
                class_counts = self.data[target_col].value_counts()
                dropout_rate = class_counts.get('Dropout', 0) / len(self.data) * 100
                print(f"\nClass Distribution:\n{class_counts}")
                print(f"Dropout Rate: {dropout_rate:.2f}%")

                # Visualize class distribution
                plt.figure(figsize=(8, 6))
                sns.countplot(x=target_col, data=self.data)
                plt.title('Class Distribution')
                plt.ylabel('Count')
                plt.xlabel('Dropout (1 = Yes, 0 = No)')
                plt.show()

                return True
            else:
                print("No file uploaded.")
                return False
        except Exception as e:
            print(f"Error loading data: {str(e)}")
            return False

    def preprocess_data(self, test_size=0.2, random_state=42, target_col='Target'):
        """Preprocess the data for model training"""
        try:
            # If target column is not 'Target', check for alternatives
            if target_col not in self.data.columns:
                print("Warning: Target column not found. Please specify the correct target column name.")
                return False

            # Separate features and target
            X = self.data.drop(columns=[target_col])
            y = self.data[target_col]

            # Handle categorical variables
            categorical_cols = X.select_dtypes(include=['object', 'category']).columns
            for col in categorical_cols:
                X[col] = self.le.fit_transform(X[col])

            # Split the data
            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
                X, y, test_size=test_size, random_state=random_state, stratify=y
            )

            # Scale the features
            self.X_train = pd.DataFrame(
                self.scaler.fit_transform(self.X_train),
                columns=X.columns
            )
            self.X_test = pd.DataFrame(
                self.scaler.transform(self.X_test),
                columns=X.columns
            )

            # Apply SMOTE to handle class imbalance
            smote = SMOTE(random_state=random_state)
            self.X_train_resampled, self.y_train_resampled = smote.fit_resample(self.X_train, self.y_train)

            print("Data preprocessing completed successfully.")
            print(f"Original training set shape: {self.X_train.shape}, Class distribution: {pd.Series(self.y_train).value_counts()}")
            print(f"Resampled training set shape: {self.X_train_resampled.shape}, Class distribution: {pd.Series(self.y_train_resampled).value_counts()}")

            return True
        except Exception as e:
            print(f"Error preprocessing data: {str(e)}")
            return False

    def train_baseline_model(self):
        """Train the baseline Logistic Regression model"""
        start_time = time.time()
        print("Training Logistic Regression baseline model...")

        # Create and train the model
        lr_model = LogisticRegression(max_iter=1000, random_state=42)
        lr_model.fit(self.X_train, self.y_train)

        # Make predictions
        y_pred = lr_model.predict(self.X_test)

        # Evaluate the model
        report = classification_report(self.y_test, y_pred, output_dict=True)
        cm = confusion_matrix(self.y_test, y_pred)

        # Calculate ROC curve
        y_pred_proba = lr_model.predict_proba(self.X_test)[:, 1]
        fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)

        execution_time = time.time() - start_time

        # Store results
        self.models['logistic_regression'] = lr_model
        self.results['logistic_regression'] = {
            'report': report,
            'confusion_matrix': cm,
            'execution_time': execution_time,
            'roc_auc': roc_auc,
            'fpr': fpr,
            'tpr': tpr
        }

        print(f"Baseline Logistic Regression model trained in {execution_time:.3f} seconds")
        print(f"Test set accuracy: {report['accuracy']:.4f}")
        print(f"ROC AUC: {roc_auc:.4f}")
        print("Classification Report:")
        print(classification_report(self.y_test, y_pred))

        # Plot confusion matrix
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Not Dropout', 'Dropout'],
                    yticklabels=['Not Dropout', 'Dropout'])
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title('Confusion Matrix - Logistic Regression')
        plt.show()

    def train_xgboost_model(self, optimize=True):
        """Train the XGBoost model with optional Bayesian optimization"""
        start_time = time.time()
        print("Training XGBoost model...")

        if optimize:
            print("Using Bayesian optimization to find optimal hyperparameters...")

            # Define the search space
            search_spaces = {
                'learning_rate': Real(0.01, 0.3),
                'max_depth': Integer(3, 10),
                'min_child_weight': Integer(1, 10),
                'gamma': Real(0, 1),
                'subsample': Real(0.5, 1.0),
                'colsample_bytree': Real(0.5, 1.0),
                'n_estimators': Integer(50, 300)
            }

            # Create the XGBoost model
            xgb_model = xgb.XGBClassifier(
                objective='binary:logistic',
                random_state=42,
                use_label_encoder=False,
                eval_metric='logloss'
            )

            # Perform Bayesian optimization
            bayes_search = BayesSearchCV(
                xgb_model,
                search_spaces,
                n_iter=10,  # Reduced for faster execution in Colab
                cv=3,        # Reduced for faster execution
                n_jobs=-1,
                random_state=42,
                scoring='roc_auc'
            )

            bayes_search.fit(self.X_train_resampled, self.y_train_resampled)

            # Get the best model
            xgb_model = bayes_search.best_estimator_
            print(f"Best hyperparameters: {bayes_search.best_params_}")
        else:
            # Use default hyperparameters
            xgb_model = xgb.XGBClassifier(
                objective='binary:logistic',
                random_state=42,
                use_label_encoder=False,
                eval_metric='logloss'
            )
            xgb_model.fit(self.X_train_resampled, self.y_train_resampled)

        # Make predictions
        y_pred = xgb_model.predict(self.X_test)

        # Evaluate the model
        report = classification_report(self.y_test, y_pred, output_dict=True)
        cm = confusion_matrix(self.y_test, y_pred)

        # Calculate ROC curve
        y_pred_proba = xgb_model.predict_proba(self.X_test)[:, 1]
        fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)

        execution_time = time.time() - start_time

        # Store results
        self.models['xgboost'] = xgb_model
        self.results['xgboost'] = {
            'report': report,
            'confusion_matrix': cm,
            'execution_time': execution_time,
            'roc_auc': roc_auc,
            'fpr': fpr,
            'tpr': tpr
        }

        # Create SHAP explainer
        self.explainer = shap.TreeExplainer(xgb_model)

        print(f"XGBoost model trained in {execution_time:.3f} seconds")
        print(f"Test set accuracy: {report['accuracy']:.4f}")
        print(f"ROC AUC: {roc_auc:.4f}")
        print("Classification Report:")
        print(classification_report(self.y_test, y_pred))

        # Plot confusion matrix
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Not Dropout', 'Dropout'],
                    yticklabels=['Not Dropout', 'Dropout'])
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title('Confusion Matrix - XGBoost')
        plt.show()

        # Set as current model
        self.current_model = 'xgboost'

    def train_lstm_model(self):
        """Train the LSTM model for temporal data"""
        if not hasattr(self, 'temporal_X_train') or self.temporal_X_train is None or len(self.temporal_X_train) == 0:
            print("No temporal data available for LSTM. Run preprocess_data with temporal=True first.")
            return

        start_time = time.time()
        print("Training LSTM model...")

        # Define the LSTM model architecture
        self.lstm_model = Sequential([
            LSTM(64, input_shape=(self.temporal_X_train.shape[1], self.temporal_X_train.shape[2]), return_sequences=True),
            Dropout(0.2),
            LSTM(32),
            Dropout(0.2),
            Dense(16, activation='relu'),
            Dense(1, activation='sigmoid')
        ])

        # Compile the model
        self.lstm_model.compile(
            optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy']
        )

        # Early stopping to prevent overfitting
        early_stopping = EarlyStopping(
            monitor='val_loss',
            patience=5,
            restore_best_weights=True
        )

        # Train the model
        history = self.lstm_model.fit(
            self.temporal_X_train, self.y_train_resampled,
            epochs=20,
            batch_size=32,
            validation_split=0.2,
            callbacks=[early_stopping],
            verbose=1
        )

        # Make predictions
        y_pred_proba = self.lstm_model.predict(self.temporal_X_test)
        y_pred = (y_pred_proba > 0.5).astype(int).flatten()

        # Evaluate the model
        report = classification_report(self.y_test, y_pred, output_dict=True)
        cm = confusion_matrix(self.y_test, y_pred)

        # Calculate ROC curve
        fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)

        execution_time = time.time() - start_time

        # Store results
        self.models['lstm'] = self.lstm_model
        self.results['lstm'] = {
            'report': report,
            'confusion_matrix': cm,
            'execution_time': execution_time,
            'roc_auc': roc_auc,
            'fpr': fpr,
            'tpr': tpr,
            'history': history.history
        }

        print(f"LSTM model trained in {execution_time:.3f} seconds")
        print(f"Test set accuracy: {report['accuracy']:.4f}")
        print(f"ROC AUC: {roc_auc:.4f}")
        print("Classification Report:")
        print(classification_report(self.y_test, y_pred))

        # Plot confusion matrix
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Not Dropout', 'Dropout'],
                    yticklabels=['Not Dropout', 'Dropout'])
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title('Confusion Matrix - LSTM')
        plt.show()

        # Plot training history
        plt.figure(figsize=(12, 5))
        plt.subplot(1, 2, 1)
        plt.plot(history.history['accuracy'])
        plt.plot(history.history['val_accuracy'])
        plt.title('Model Accuracy')
        plt.ylabel('Accuracy')
        plt.xlabel('Epoch')
        plt.legend(['Train', 'Validation'], loc='lower right')

        plt.subplot(1, 2, 2)
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('Model Loss')
        plt.ylabel('Loss')
        plt.xlabel('Epoch')
        plt.legend(['Train', 'Validation'], loc='upper right')
        plt.tight_layout()
        plt.show()

        # Set as current model
        self.current_model = 'lstm'

    def compare_models(self):
        """Compare all trained models"""
        if not self.results:
            print("No models trained yet. Please train at least one model first.")
            return

        print("Model Comparison")
        print("---------------")

        # Create comparison table
        comparison = {
            'Model': [],
            'Accuracy': [],
            'Precision (Dropout)': [],
            'Recall (Dropout)': [],
            'F1-Score (Dropout)': [],
            'ROC AUC': [],
            'Execution Time (s)': []
        }

        # Collect results for each model
        for model_name, result in self.results.items():
            comparison['Model'].append(model_name)
            comparison['Accuracy'].append(result['report']['accuracy'])
            comparison['Precision (Dropout)'].append(result['report']['1']['precision'])
            comparison['Recall (Dropout)'].append(result['report']['1']['recall'])
            comparison['F1-Score (Dropout)'].append(result['report']['1']['f1-score'])
            comparison['ROC AUC'].append(result['roc_auc'])
            comparison['Execution Time (s)'].append(result['execution_time'])

        # Display comparison table
        comparison_df = pd.DataFrame(comparison)
        display(comparison_df)

        # Plot ROC curves for all models
        plt.figure(figsize=(10, 8))

        for model_name, result in self.results.items():
            plt.plot(result['fpr'], result['tpr'], label=f'{model_name} (AUC = {result["roc_auc"]:.4f})')

        plt.plot([0, 1], [0, 1], 'k--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('ROC Curves for all Models')
        plt.legend(loc="lower right")
        plt.show()

        # Bar chart comparing key metrics
        plt.figure(figsize=(12, 6))

        metrics = ['Accuracy', 'Precision (Dropout)', 'Recall (Dropout)', 'F1-Score (Dropout)']
        x = np.arange(len(metrics))
        width = 0.2
        multiplier = 0

        for model_name, result in self.results.items():
            offset = width * multiplier
            values = [
                result['report']['accuracy'],
                result['report']['1']['precision'],
                result['report']['1']['recall'],
                result['report']['1']['f1-score']
            ]

            plt.bar(x + offset, values, width, label=model_name)
            multiplier += 1

        plt.ylabel('Score')
        plt.title('Performance Comparison')
        plt.xticks(x + width, metrics)
        plt.legend(loc='upper left')
        plt.ylim(0, 1)
        plt.tight_layout()
        plt.show()

    def explain_predictions(self, num_samples=5):
        """Explain model predictions using SHAP values"""
        if self.current_model != 'xgboost' or 'xgboost' not in self.models:
            print("SHAP explanation is currently only available for XGBoost models.")
            print("Please train an XGBoost model first.")
            return

        print("Generating SHAP explanations for model predictions...")

        # Calculate SHAP values for the test set
        shap_values = self.explainer.shap_values(self.X_test)

        # Summary plot
        plt.figure(figsize=(10, 8))
        shap.summary_plot(shap_values, self.X_test, plot_type="bar", show=False)
        plt.title("Feature Importance Based on SHAP Values")
        plt.tight_layout()
        plt.show()

        # Detailed summary plot
        plt.figure(figsize=(12, 10))
        shap.summary_plot(shap_values, self.X_test, show=False)
        plt.title("Feature Impact on Predictions")
        plt.tight_layout()
        plt.show()

        # Individual explanations for a few samples
        print(f"\nDetailed explanations for {num_samples} sample predictions:")

        for i in range(min(num_samples, len(self.X_test))):
            plt.figure(figsize=(12, 6))

            # Get actual and predicted values
            actual = self.y_test.iloc[i]
            prediction = self.models['xgboost'].predict_proba([self.X_test.iloc[i]])[0][1]

            # Create force plot
            shap.force_plot(
                base_value=self.explainer.expected_value,
                shap_values=shap_values[i],
                features=self.X_test.iloc[i],
                feature_names=self.X_test.columns,
                matplotlib=True,
                show=False
            )

            plt.title(f"Sample {i+1}: Actual={actual}, Predicted Probability={prediction:.4f}")
            plt.tight_layout()
            plt.show()

            # Print top 5 contributing features
            feature_importance = pd.DataFrame({
                'Feature': self.X_test.columns,
                'Importance': np.abs(shap_values[i])
            }).sort_values('Importance', ascending=False).head(5)

            print(f"Top contributing features for Sample {i+1}:")
            display(feature_importance)
            print("\n" + "-"*50 + "\n")

    def predict_dropout_risk(self, student_data=None):
        """Predict dropout risk for a single student or a sample from test set"""
        if not self.models:
            print("No models trained yet. Please train at least one model first.")
            return

        if student_data is None:
            # Use a sample from the test set
            sample_idx = np.random.choice(len(self.X_test))
            student_data = self.X_test.iloc[sample_idx]
            actual_label = self.y_test.iloc[sample_idx]
            print(f"Using sample {sample_idx} from test set.")
            print(f"Actual dropout status: {'Yes' if actual_label == 'Dropout' else 'No'}")

        # Make predictions with all available models
        predictions = {}

        for model_name, model in self.models.items():
            start_time = time.time()

            if model_name == 'lstm' and hasattr(self, 'temporal_X_test'):
                # For LSTM, reshape the data
                sample_data = self.temporal_X_test[sample_idx:sample_idx+1]
                pred_prob = model.predict(sample_data)[0][0]
            else:
                # For other models
                if isinstance(student_data, pd.Series):
                    sample_data = student_data.values.reshape(1, -1)
                else:
                    sample_data = student_data.reshape(1, -1)

                pred_prob = model.predict_proba(sample_data)[0][1]

            execution_time = time.time() - start_time

            risk_level = "High" if pred_prob >= 0.7 else "Medium" if pred_prob >= 0.4 else "Low"

            predictions[model_name] = {
                'probability': pred_prob,
                'risk_level': risk_level,
                'execution_time': execution_time
            }

        # Display predictions
        print("\nDropout Risk Predictions")
        print("------------------------")

        pred_df = pd.DataFrame({
            'Model': list(predictions.keys()),
            'Dropout Probability': [pred['probability'] for pred in predictions.values()],
            'Risk Level': [pred['risk_level'] for pred in predictions.values()],
            'Execution Time (s)': [pred['execution_time'] for pred in predictions.values()]
        })

        display(pred_df)

        # Visualize predictions
        plt.figure(figsize=(10, 6))
        bars = plt.barh(pred_df['Model'], pred_df['Dropout Probability'], color=['green' if p < 0.4 else 'orange' if p < 0.7 else 'red' for p in pred_df['Dropout Probability']])

        plt.title('Dropout Risk Probability by Model')
        plt.xlabel('Probability')
        plt.xlim(0, 1)

        # Add threshold lines
        plt.axvline(x=0.4, color='orange', linestyle='--', alpha=0.7, label='Medium Risk Threshold')
        plt.axvline(x=0.7, color='red', linestyle='--', alpha=0.7, label='High Risk Threshold')

        # Add probability values on bars
        for bar, prob in zip(bars, pred_df['Dropout Probability']):
            plt.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2, f'{prob:.2f}', va='center')

        plt.legend()
        plt.tight_layout()
        plt.show()

        # If XGBoost is available and used for prediction, provide SHAP explanation
        if 'xgboost' in self.models and self.explainer is not None:
            print("\nExplanation for XGBoost prediction:")

            # Calculate SHAP values
            if isinstance(student_data, pd.Series):
                explanation = self.explainer.shap_values(student_data.values.reshape(1, -1))[0]
            else:
                explanation = self.explainer.shap_values(student_data.reshape(1, -1))[0]

            # Plot explanation
            plt.figure(figsize=(12, 6))
            shap.force_plot(
                base_value=self.explainer.expected_value,
                shap_values=explanation,
                features=student_data,
                feature_names=self.X_test.columns,
                matplotlib=True,
                show=False
            )
            plt.title('Factors Influencing Dropout Prediction')
            plt.tight_layout()
            plt.show()

            # Provide actionable insights
            feature_impact = pd.DataFrame({
                'Feature': self.X_test.columns,
                'Impact': explanation
            }).sort_values('Impact', ascending=False)

            # Top positive factors (increasing dropout risk)
            positive_factors = feature_impact[feature_impact['Impact'] > 0].head(5)

            # Top negative factors (decreasing dropout risk)
            negative_factors = feature_impact[feature_impact['Impact'] < 0].head(5)

            print("\nActionable Insights:")
            print("-------------------")

            if not positive_factors.empty:
                print("Top risk factors to address:")
                for i, (feature, impact) in enumerate(zip(positive_factors['Feature'], positive_factors['Impact']), 1):
                    print(f"{i}. {feature}: Contributes {impact:.4f} to dropout risk")

            if not negative_factors.empty:
                print("\nProtective factors to maintain:")
                for i, (feature, impact) in enumerate(zip(negative_factors['Feature'], negative_factors['Impact']), 1):
                    print(f"{i}. {feature}: Reduces dropout risk by {abs(impact):.4f}")

            print("\nRecommendations:")
            print("For high-risk students, consider:")
            print("1. Academic interventions targeting specific subjects")
            print("2. Increased advisor check-ins")
            print("3. Connecting to support services")
            print("4. Peer mentoring programs")
            print("5. Financial aid review if applicable")

# Create UI components
def create_ui():
    """Create the UI for the Student Dropout Prediction System"""
    # File upload widget
    upload_button = widgets.FileUpload(
        description='Upload Dataset',
        accept='.csv, .xlsx, .xls',
        multiple=False,
        layout=Layout(width='300px')
    )

    # Analysis options
    temporal_checkbox =    widgets.Checkbox(
        value=True,
        description='Process Temporal Data (for LSTM)',
        disabled=False
    )

    optimize_checkbox = widgets.Checkbox(
        value=True,
        description='Use Bayesian Optimization',
        disabled=False
    )

    # Target column selector
    target_input = widgets.Text(
        value='Target',
        placeholder='Target',
        description='Target Column:',
        disabled=False
    )

    # Button widgets
    analyze_button = widgets.Button(
        description='Analyze Data',
        disabled=False,
        button_style='info',
        tooltip='Analyze the dataset',
        icon='chart-line'
    )

    train_baseline_button = widgets.Button(
        description='Train Baseline (LR)',
        disabled=True,
        button_style='',
        tooltip='Train Logistic Regression model',
        icon='play'
    )

    train_xgboost_button = widgets.Button(
        description='Train XGBoost',
        disabled=True,
        button_style='',
        tooltip='Train XGBoost model',
        icon='play'
    )

    train_lstm_button = widgets.Button(
        description='Train LSTM',
        disabled=True,
        button_style='',
        tooltip='Train LSTM model',
        icon='play'
    )

    compare_button = widgets.Button(
        description='Compare Models',
        disabled=True,
        button_style='',
        tooltip='Compare all trained models',
        icon='balance-scale'
    )

    explain_button = widgets.Button(
        description='Explain Predictions',
        disabled=True,
        button_style='',
        tooltip='Explain model predictions using SHAP',
        icon='question-circle'
    )

    predict_button = widgets.Button(
        description='Predict Sample',
        disabled=True,
        button_style='',
        tooltip='Predict dropout risk for a sample',
        icon='user'
    )

    # Output area
    output = widgets.Output()

    # Progress indicator
    progress = widgets.IntProgress(
        value=0,
        min=0,
        max=10,
        description='Progress:',
        style={'description_width': 'initial'},
        orientation='horizontal'
    )

    # Status message
    status = widgets.HTML(value="<p>Upload a dataset to begin.</p>")

    # Arrange the widgets
    header = widgets.HTML(value="<h1>Student Dropout Prediction System</h1>")
    description = widgets.HTML(
        value="""<p>This system uses advanced machine learning techniques to predict student dropout risk:</p>
        <ul>
            <li><strong>XGBoost:</strong> Captures non-linear relationships between features</li>
            <li><strong>LSTM Networks:</strong> Processes sequential data to identify trends over time</li>
            <li><strong>SMOTE:</strong> Balances imbalanced datasets</li>
            <li><strong>SHAP:</strong> Provides explainable predictions for actionable interventions</li>
            <li><strong>Bayesian Optimization:</strong> Optimizes hyperparameters for better performance</li>
        </ul>"""
    )

    data_section = widgets.VBox([
        widgets.HTML(value="<h2>Data Input</h2>"),
        widgets.HBox([upload_button, target_input]),
        widgets.HBox([temporal_checkbox, optimize_checkbox]),
        analyze_button
    ])

    model_section = widgets.VBox([
        widgets.HTML(value="<h2>Model Training</h2>"),
        widgets.HBox([train_baseline_button, train_xgboost_button, train_lstm_button]),
        widgets.HBox([compare_button, explain_button, predict_button])
    ])

    status_section = widgets.VBox([
        progress,
        status
    ])

    # Create the main layout
    main_layout = widgets.VBox([
        header,
        description,
        data_section,
        model_section,
        status_section,
        output
    ])

    # Initialize the predictor
    predictor = StudentDropoutPredictor()

    # Define button callbacks
    def on_upload_change(change):
        with output:
            if upload_button.value:
                status.value = "<p>Dataset uploaded. Click 'Analyze Data' to proceed.</p>"
                analyze_button.disabled = False

    def on_analyze_click(b):
        with output:
            clear_output()
            status.value = "<p>Analyzing dataset...</p>"
            progress.value = 2

            if upload_button.value:
                file_info = list(upload_button.value.items())[0][1]
                if predictor.load_data(file_info):
                    status.value = "<p>Dataset loaded. Processing data...</p>"
                    progress.value = 5

                    if predictor.preprocess_data(target_col=target_input.value):
                        status.value = "<p>Data processed successfully. Ready to train models.</p>"
                        progress.value = 10

                        # Enable training buttons
                        train_baseline_button.disabled = False
                        train_xgboost_button.disabled = False
                        if temporal_checkbox.value and predictor.semester_columns:
                            train_lstm_button.disabled = False
                        else:
                            train_lstm_button.disabled = True
                            status.value += "<p>Note: LSTM training disabled as no temporal data detected.</p>"
                    else:
                        status.value = "<p>Error preprocessing data.</p>"
                        progress.value = 0
                else:
                    status.value = "<p>Error loading dataset.</p>"
                    progress.value = 0
            else:
                status.value = "<p>Please upload a dataset first.</p>"
                progress.value = 0

    def on_train_baseline_click(b):
        with output:
            clear_output()
            status.value = "<p>Training Logistic Regression model...</p>"
            progress.value = 3

            predictor.train_baseline_model()

            status.value = "<p>Logistic Regression model trained successfully.</p>"
            progress.value = 10
            compare_button.disabled = False
            predict_button.disabled = False

    def on_train_xgboost_click(b):
        with output:
            clear_output()
            status.value = "<p>Training XGBoost model...</p>"
            progress.value = 3

            predictor.train_xgboost_model(optimize=optimize_checkbox.value)

            status.value = "<p>XGBoost model trained successfully.</p>"
            progress.value = 10
            compare_button.disabled = False
            predict_button.disabled = False
            explain_button.disabled = False

    def on_train_lstm_click(b):
        with output:
            clear_output()
            status.value = "<p>Training LSTM model...</p>"
            progress.value = 3

            predictor.train_lstm_model()

            status.value = "<p>LSTM model trained successfully.</p>"
            progress.value = 10
            compare_button.disabled = False
            predict_button.disabled = False

    def on_compare_click(b):
        with output:
            clear_output()
            status.value = "<p>Comparing models...</p>"
            progress.value = 5

            predictor.compare_models()

            status.value = "<p>Model comparison completed.</p>"
            progress.value = 10

    def on_explain_click(b):
        with output:
            clear_output()
            status.value = "<p>Generating model explanations...</p>"
            progress.value = 5

            predictor.explain_predictions()

            status.value = "<p>Model explanations generated.</p>"
            progress.value = 10

    def on_predict_click(b):
        with output:
            clear_output()
            status.value = "<p>Predicting dropout risk for a sample...</p>"
            progress.value = 5

            predictor.predict_dropout_risk()

            status.value = "<p>Prediction completed.</p>"
            progress.value = 10

    # Register callbacks
    upload_button.observe(on_upload_change, names='value')
    analyze_button.on_click(on_analyze_click)
    train_baseline_button.on_click(on_train_baseline_click)
    train_xgboost_button.on_click(on_train_xgboost_click)
    train_lstm_button.on_click(on_train_lstm_click)
    compare_button.on_click(on_compare_click)
    explain_button.on_click(on_explain_click)
    predict_button.on_click(on_predict_click)

    return main_layout

# Sample data generator for testing purposes
def generate_sample_data(n_samples=1000, dropout_rate=0.195):
    """Generate synthetic student data for testing the system"""
    np.random.seed(42)

    # Define the features
    student_ids = np.arange(1, n_samples + 1)
    marital_status = np.random.choice([1, 2], n_samples)  # 1: Single, 2: Married
    application_mode = np.random.randint(1, 13, n_samples)  # Random application modes
    application_order = np.random.randint(1, 6, n_samples)  # Random application orders
    course = np.random.randint(1, 20, n_samples)  # Random course IDs
    attendance = np.random.choice([1, 2], n_samples)  # 1: Daytime, 2: Evening
    previous_qualification = np.random.randint(1, 5, n_samples)  # Random qualifications
    nationality = np.random.randint(1, 3, n_samples)  # 1: National, 2: International
    mothers_qualification = np.random.randint(1, 5, n_samples)  # Random qualifications
    fathers_qualification = np.random.randint(1, 5, n_samples)  # Random qualifications
    mothers_occupation = np.random.randint(1, 5, n_samples)  # Random occupations
    fathers_occupation = np.random.randint(1, 5, n_samples)  # Random occupations
    displaced = np.random.choice([0, 1], n_samples)  # 0: No, 1: Yes
    educational_special_needs = np.random.choice([0, 1], n_samples)  # 0: No, 1: Yes
    debtor = np.random.choice([0, 1], n_samples)  # 0: No, 1: Yes
    tuition_fees_up_to_date = np.random.choice([0, 1], n_samples)  # 0: No, 1: Yes
    gender = np.random.choice(['M', 'F'], n_samples)  # Random gender
    scholarship_holder = np.random.choice([0, 1], n_samples)  # 0: No, 1: Yes
    age_at_enrollment = np.random.randint(18, 30, n_samples)  # Random ages
    international = np.random.choice([0, 1], n_samples)  # 0: No, 1: Yes
    curricular_units_1st_sem_credited = np.random.randint(0, 10, n_samples)
    curricular_units_1st_sem_enrolled = np.random.randint(0, 10, n_samples)
    curricular_units_1st_sem_evaluations = np.random.randint(0, 10, n_samples)
    curricular_units_1st_sem_approved = np.random.randint(0, 10, n_samples)
    curricular_units_1st_sem_grade = np.random.uniform(0, 20, n_samples)
    curricular_units_1st_sem_without_evaluations = np.random.randint(0, 10, n_samples)
    curricular_units_2nd_sem_credited = np.random.randint(0, 10, n_samples)
    curricular_units_2nd_sem_enrolled = np.random.randint(0, 10, n_samples)
    curricular_units_2nd_sem_evaluations = np.random.randint(0, 10, n_samples)
    curricular_units_2nd_sem_approved = np.random.randint(0, 10, n_samples)
    curricular_units_2nd_sem_grade = np.random.uniform(0, 20, n_samples)
    curricular_units_2nd_sem_without_evaluations = np.random.randint(0, 10, n_samples)
    unemployment_rate = np.random.uniform(5, 15, n_samples)  # Random unemployment rates
    inflation_rate = np.random.uniform(-1, 5, n_samples)  # Random inflation rates
    gdp = np.random.uniform(1, 5, n_samples)  # Random GDP values

    # Create initial DataFrame
    df = pd.DataFrame({
        'student_id': student_ids,
        'Marital status': marital_status,
        'Application mode': application_mode,
        'Application order': application_order,
        'Course': course,
        'Daytime/evening attendance': attendance,
        'Previous qualification': previous_qualification,
        'Nacionality': nationality,
        'Mother\'s qualification': mothers_qualification,
        'Father\'s qualification': fathers_qualification,
        'Mother\'s occupation': mothers_occupation,
        'Father\'s occupation': fathers_occupation,
        'Displaced': displaced,
        'Educational special needs': educational_special_needs,
        'Debtor': debtor,
        'Tuition fees up to date': tuition_fees_up_to_date,
        'Gender': gender,
        'Scholarship holder': scholarship_holder,
        'Age at enrollment': age_at_enrollment,
        'International': international,
        'Curricular units 1st sem (credited)': curricular_units_1st_sem_credited,
        'Curricular units 1st sem (enrolled)': curricular_units_1st_sem_enrolled,
        'Curricular units 1st sem (evaluations)': curricular_units_1st_sem_evaluations,
        'Curricular units 1st sem (approved)': curricular_units_1st_sem_approved,
        'Curricular units 1st sem (grade)': curricular_units_1st_sem_grade,
        'Curricular units 1st sem (without evaluations)': curricular_units_1st_sem_without_evaluations,
        'Curricular units 2nd sem (credited)': curricular_units_2nd_sem_credited,
        'Curricular units 2nd sem (enrolled)': curricular_units_2nd_sem_enrolled,
        'Curricular units 2nd sem (evaluations)': curricular_units_2nd_sem_evaluations,
        'Curricular units 2nd sem (approved)': curricular_units_2nd_sem_approved,
        'Curricular units 2nd sem (grade)': curricular_units_2nd_sem_grade,
        'Curricular units 2nd sem (without evaluations)': curricular_units_2nd_sem_without_evaluations,
        'Unemployment rate': unemployment_rate,
        'Inflation rate': inflation_rate,
        'GDP': gdp,
        'Target': np.random.choice(['Dropout', 'Graduate'], n_samples, p=[dropout_rate / 100, 1 - dropout_rate / 100])
    })

    print(f"Generated sample dataset with {n_samples} students.")
    print(f"Dropout rate: {df['Target'].value_counts(normalize=True)['Dropout'] * 100:.1f}%")

    return df

# Main execution
if __name__ == "__main__":
    print("Student Dropout Prediction System")
    print("================================")
    print("This system uses advanced machine learning techniques to predict student dropout risk.")

    # Display the UI
    main_ui = create_ui()
    display(main_ui)

    # Output information about sample data
    print("\nNo dataset? You can generate a sample dataset for testing:")
    print("```python")
    print("sample_data = generate_sample_data(n_samples=1000)")
    print("sample_data.to_csv('student_data.csv', index=False)")
    print("```")

# Student Dropout Prediction System
# Advanced implementation with XGBoost, LSTM, SMOTE, SHAP and Bayesian Optimization

# Install required packages
!pip install xgboost shap imbalanced-learn scikit-optimize matplotlib seaborn tensorflow pandas numpy scikit-learn yellowbrick

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from sklearn.linear_model import LogisticRegression
import xgboost as xgb
from imblearn.over_sampling import SMOTE
import shap
from skopt import BayesSearchCV
from skopt.space import Real, Integer
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout
from tensorflow.keras.callbacks import EarlyStopping
import io
import time
import warnings
warnings.filterwarnings('ignore')

# Define the main class for the Student Dropout Prediction System
class StudentDropoutPredictor:
    def __init__(self):
        self.data = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.X_train_resampled = None
        self.y_train_resampled = None
        self.models = {}
        self.results = {}
        self.temporal_features = []
        self.scaler = StandardScaler()
        self.le = LabelEncoder()
        self.explainer = None
        self.semester_columns = []
        self.lstm_model = None
        self.current_model = None

    def load_data(self, file_path):
        """Load the dataset from the specified file path"""
        try:
            # Load the data based on the file extension
            if file_path.endswith('.csv'):
                self.data = pd.read_csv(file_path)
            elif file_path.endswith(('.xls', '.xlsx')):
                self.data = pd.read_excel(file_path)
            else:
                raise ValueError("Unsupported file format. Please upload a CSV or Excel file.")

            # Display data info
            print(f"Dataset loaded successfully. Shape: {self.data.shape}")
            print("\nData Sample:")
            display(self.data.head())
            print("\nData Info:")
            self.data.info()
            print("\nSummary Statistics:")
            display(self.data.describe())
            print("\nMissing Values:")
            display(self.data.isnull().sum())

            # Check for class imbalance
            if 'Target' in self.data.columns:  # Adjusted to match your dataset
                target_col = 'Target'
            else:
                print("Warning: Could not identify target column. Please rename your target column to 'Target'.")
                return

            # Class distribution
            class_counts = self.data[target_col].value_counts()
            dropout_rate = class_counts.get('Dropout', 0) / len(self.data) * 100
            print(f"\nClass Distribution:\n{class_counts}")
            print(f"Dropout Rate: {dropout_rate:.2f}%")

            # Visualize class distribution
            plt.figure(figsize=(8, 6))
            sns.countplot(x=target_col, data=self.data)
            plt.title('Class Distribution')
            plt.ylabel('Count')
            plt.xlabel('Dropout (1 = Yes, 0 = No)')
            plt.show()

            return True
        except Exception as e:
            print(f"Error loading data: {str(e)}")
            return False

    def preprocess_data(self, test_size=0.2, random_state=42, target_col='Target'):
        """Preprocess the data for model training"""
        try:
            # If target column is not 'Target', check for alternatives
            if target_col not in self.data.columns:
                print("Warning: Target column not found. Please specify the correct target column name.")
                return False

            # Separate features and target
            X = self.data.drop(columns=[target_col])
            y = self.data[target_col]

            # Handle categorical variables
            categorical_cols = X.select_dtypes(include=['object', 'category']).columns
            for col in categorical_cols:
                X[col] = self.le.fit_transform(X[col])

            # Split the data
            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
                X, y, test_size=test_size, random_state=random_state, stratify=y
            )

            # Scale the features
            self.X_train = pd.DataFrame(
                self.scaler.fit_transform(self.X_train),
                columns=X.columns
            )
            self.X_test = pd.DataFrame(
                self.scaler.transform(self.X_test),
                columns=X.columns
            )

            # Apply SMOTE to handle class imbalance
            smote = SMOTE(random_state=random_state)
            self.X_train_resampled, self.y_train_resampled = smote.fit_resample(self.X_train, self.y_train)

            print("Data preprocessing completed successfully.")
            print(f"Original training set shape: {self.X_train.shape}, Class distribution: {pd.Series(self.y_train).value_counts()}")
            print(f"Resampled training set shape: {self.X_train_resampled.shape}, Class distribution: {pd.Series(self.y_train_resampled).value_counts()}")

            return True
        except Exception as e:
            print(f"Error preprocessing data: {str(e)}")
            return False

    def train_baseline_model(self):
        """Train the baseline Logistic Regression model"""
        start_time = time.time()
        print("Training Logistic Regression baseline model...")

        # Create and train the model
        lr_model = LogisticRegression(max_iter=1000, random_state=42)
        lr_model.fit(self.X_train, self.y_train)

        # Make predictions
        y_pred = lr_model.predict(self.X_test)

        # Evaluate the model
        report = classification_report(self.y_test, y_pred, output_dict=True)
        cm = confusion_matrix(self.y_test, y_pred)

        # Calculate ROC curve
        y_pred_proba = lr_model.predict_proba(self.X_test)[:, 1]
        fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)

        execution_time = time.time() - start_time

        # Store results
        self.models['logistic_regression'] = lr_model
        self.results['logistic_regression'] = {
            'report': report,
            'confusion_matrix': cm,
            'execution_time': execution_time,
            'roc_auc': roc_auc,
            'fpr': fpr,
            'tpr': tpr
        }

        print(f"Baseline Logistic Regression model trained in {execution_time:.3f} seconds")
        print(f"Test set accuracy: {report['accuracy']:.4f}")
        print(f"ROC AUC: {roc_auc:.4f}")
        print("Classification Report:")
        print(classification_report(self.y_test, y_pred))

        # Plot confusion matrix
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Not Dropout', 'Dropout'],
                    yticklabels=['Not Dropout', 'Dropout'])
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title('Confusion Matrix - Logistic Regression')
        plt.show()

    def train_xgboost_model(self, optimize=True):
        """Train the XGBoost model with optional Bayesian optimization"""
        start_time = time.time()
        print("Training XGBoost model...")

        if optimize:
            print("Using Bayesian optimization to find optimal hyperparameters...")

            # Define the search space
            search_spaces = {
                'learning_rate': Real(0.01, 0.3),
                'max_depth': Integer(3, 10),
                'min_child_weight': Integer(1, 10),
                'gamma': Real(0, 1),
                'subsample': Real(0.5, 1.0),
                'colsample_bytree': Real(0.5, 1.0),
                'n_estimators': Integer(50, 300)
            }

            # Create the XGBoost model
            xgb_model = xgb.XGBClassifier(
                objective='binary:logistic',
                random_state=42,
                use_label_encoder=False,
                eval_metric='logloss'
            )

            # Perform Bayesian optimization
            bayes_search = BayesSearchCV(
                xgb_model,
                search_spaces,
                n_iter=10,  # Reduced for faster execution
                cv=3,        # Reduced for faster execution
                n_jobs=-1,
                random_state=42,
                scoring='roc_auc'
            )

            bayes_search.fit(self.X_train_resampled, self.y_train_resampled)

            # Get the best model
            xgb_model = bayes_search.best_estimator_
            print(f"Best hyperparameters: {bayes_search.best_params_}")
        else:
            # Use default hyperparameters
            xgb_model = xgb.XGBClassifier(
                objective='binary:logistic',
                random_state=42,
                use_label_encoder=False,
                eval_metric='logloss'
            )
            xgb_model.fit(self.X_train_resampled, self.y_train_resampled)

        # Make predictions
        y_pred = xgb_model.predict(self.X_test)

        # Evaluate the model
        report = classification_report(self.y_test, y_pred, output_dict=True)
        cm = confusion_matrix(self.y_test, y_pred)

        # Calculate ROC curve
        y_pred_proba = xgb_model.predict_proba(self.X_test)[:, 1]
        fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)

        execution_time = time.time() - start_time

        # Store results
        self.models['xgboost'] = xgb_model
        self.results['xgboost'] = {
            'report': report,
            'confusion_matrix': cm,
            'execution_time': execution_time,
            'roc_auc': roc_auc,
            'fpr': fpr,
            'tpr': tpr
        }

        # Create SHAP explainer
        self.explainer = shap.TreeExplainer(xgb_model)

        print(f"XGBoost model trained in {execution_time:.3f} seconds")
        print(f"Test set accuracy: {report['accuracy']:.4f}")
        print(f"ROC AUC: {roc_auc:.4f}")
        print("Classification Report:")
        print(classification_report(self.y_test, y_pred))

        # Plot confusion matrix
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Not Dropout', 'Dropout'],
                    yticklabels=['Not Dropout', 'Dropout'])
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title('Confusion Matrix - XGBoost')
        plt.show()

        # Set as current model
        self.current_model = 'xgboost'

    def train_lstm_model(self):
        """Train the LSTM model for temporal data"""
        if not hasattr(self, 'temporal_X_train') or self.temporal_X_train is None or len(self.temporal_X_train) == 0:
            print("No temporal data available for LSTM. Run preprocess_data with temporal=True first.")
            return

        start_time = time.time()
        print("Training LSTM model...")

        # Define the LSTM model architecture
        self.lstm_model = Sequential([
            LSTM(64, input_shape=(self.temporal_X_train.shape[1], self.temporal_X_train.shape[2]), return_sequences=True),
            Dropout(0.2),
            LSTM(32),
            Dropout(0.2),
            Dense(16, activation='relu'),
            Dense(1, activation='sigmoid')
        ])

        # Compile the model
        self.lstm_model.compile(
            optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy']
        )

        # Early stopping to prevent overfitting
        early_stopping = EarlyStopping(
            monitor='val_loss',
            patience=5,
            restore_best_weights=True
        )

        # Train the model
        history = self.lstm_model.fit(
            self.temporal_X_train, self.y_train_resampled,
            epochs=20,
            batch_size=32,
            validation_split=0.2,
            callbacks=[early_stopping],
            verbose=1
        )

        # Make predictions
        y_pred_proba = self.lstm_model.predict(self.temporal_X_test)
        y_pred = (y_pred_proba > 0.5).astype(int).flatten()

        # Evaluate the model
        report = classification_report(self.y_test, y_pred, output_dict=True)
        cm = confusion_matrix(self.y_test, y_pred)

        # Calculate ROC curve
        fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)

        execution_time = time.time() - start_time

        # Store results
        self.models['lstm'] = self.lstm_model
        self.results['lstm'] = {
            'report': report,
            'confusion_matrix': cm,
            'execution_time': execution_time,
            'roc_auc': roc_auc,
            'fpr': fpr,
            'tpr': tpr,
            'history': history.history
        }

        print(f"LSTM model trained in {execution_time:.3f} seconds")
        print(f"Test set accuracy: {report['accuracy']:.4f}")
        print(f"ROC AUC: {roc_auc:.4f}")
        print("Classification Report:")
        print(classification_report(self.y_test, y_pred))

        # Plot confusion matrix
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Not Dropout', 'Dropout'],
                    yticklabels=['Not Dropout', 'Dropout'])
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title('Confusion Matrix - LSTM')
        plt.show()

        # Plot training history
        plt.figure(figsize=(12, 5))
        plt.subplot(1, 2, 1)
        plt.plot(history.history['accuracy'])
        plt.plot(history.history['val_accuracy'])
        plt.title('Model Accuracy')
        plt.ylabel('Accuracy')
        plt.xlabel('Epoch')
        plt.legend(['Train', 'Validation'], loc='lower right')

        plt.subplot(1, 2, 2)
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('Model Loss')
        plt.ylabel('Loss')
        plt.xlabel('Epoch')
        plt.legend(['Train', 'Validation'], loc='upper right')
        plt.tight_layout()
        plt.show()

        # Set as current model
        self.current_model = 'lstm'

    def compare_models(self):
        """Compare all trained models"""
        if not self.results:
            print("No models trained yet. Please train at least one model first.")
            return

        print("Model Comparison")
        print("---------------")

        # Create comparison table
        comparison = {
            'Model': [],
            'Accuracy': [],
            'Precision (Dropout)': [],
            'Recall (Dropout)': [],
            'F1-Score (Dropout)': [],
            'ROC AUC': [],
            'Execution Time (s)': []
        }

        # Collect results for each model
        for model_name, result in self.results.items():
            comparison['Model'].append(model_name)
            comparison['Accuracy'].append(result['report']['accuracy'])
            comparison['Precision (Dropout)'].append(result['report']['1']['precision'])
            comparison['Recall (Dropout)'].append(result['report']['1']['recall'])
            comparison['F1-Score (Dropout)'].append(result['report']['1']['f1-score'])
            comparison['ROC AUC'].append(result['roc_auc'])
            comparison['Execution Time (s)'].append(result['execution_time'])

        # Display comparison table
        comparison_df = pd.DataFrame(comparison)
        display(comparison_df)

        # Plot ROC curves for all models
        plt.figure(figsize=(10, 8))

        for model_name, result in self.results.items():
            plt.plot(result['fpr'], result['tpr'], label=f'{model_name} (AUC = {result["roc_auc"]:.4f})')

        plt.plot([0, 1], [0, 1], 'k--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('ROC Curves for all Models')
        plt.legend(loc="lower right")
        plt.show()

        # Bar chart comparing key metrics
        plt.figure(figsize=(12, 6))

        metrics = ['Accuracy', 'Precision (Dropout)', 'Recall (Dropout)', 'F1-Score (Dropout)']
        x = np.arange(len(metrics))
        width = 0.2
        multiplier = 0

        for model_name, result in self.results.items():
            offset = width * multiplier
            values = [
                result['report']['accuracy'],
                result['report']['1']['precision'],
                result['report']['1']['recall'],
                result['report']['1']['f1-score']
            ]

            plt.bar(x + offset, values, width, label=model_name)
            multiplier += 1

        plt.ylabel('Score')
        plt.title('Performance Comparison')
        plt.xticks(x + width, metrics)
        plt.legend(loc='upper left')
        plt.ylim(0, 1)
        plt.tight_layout()
        plt.show()

    def explain_predictions(self, num_samples=5):
        """Explain model predictions using SHAP values"""
        if self.current_model != 'xgboost' or 'xgboost' not in self.models:
            print("SHAP explanation is currently only available for XGBoost models.")
            print("Please train an XGBoost model first.")
            return

        print("Generating SHAP explanations for model predictions...")

        # Calculate SHAP values for the test set
        shap_values = self.explainer.shap_values(self.X_test)

        # Summary plot
        plt.figure(figsize=(10, 8))
        shap.summary_plot(shap_values, self.X_test, plot_type="bar", show=False)
        plt.title("Feature Importance Based on SHAP Values")
        plt.tight_layout()
        plt.show()

        # Detailed summary plot
        plt.figure(figsize=(12, 10))
        shap.summary_plot(shap_values, self.X_test, show=False)
        plt.title("Feature Impact on Predictions")
        plt.tight_layout()
        plt.show()

        # Individual explanations for a few samples
        print(f"\nDetailed explanations for {num_samples} sample predictions:")

        for i in range(min(num_samples, len(self.X_test))):
            plt.figure(figsize=(12, 6))

            # Get actual and predicted values
            actual = self.y_test.iloc[i]
            prediction = self.models['xgboost'].predict_proba([self.X_test.iloc[i]])[0][1]

            # Create force plot
            shap.force_plot(
                base_value=self.explainer.expected_value,
                shap_values=shap_values[i],
                features=self.X_test.iloc[i],
                feature_names=self.X_test.columns,
                matplotlib=True,
                show=False
            )

            plt.title(f"Sample {i+1}: Actual={actual}, Predicted Probability={prediction:.4f}")
            plt.tight_layout()
            plt.show()

            # Print top 5 contributing features
            feature_importance = pd.DataFrame({
                'Feature': self.X_test.columns,
                'Importance': np.abs(shap_values[i])
            }).sort_values('Importance', ascending=False).head(5)

            print(f"Top contributing features for Sample {i+1}:")
            display(feature_importance)
            print("\n" + "-"*50 + "\n")

    def predict_dropout_risk(self, student_data=None):
        """Predict dropout risk for a single student or a sample from test set"""
        if not self.models:
            print("No models trained yet. Please train at least one model first.")
            return

        if student_data is None:
            # Use a sample from the test set
            sample_idx = np.random.choice(len(self.X_test))
            student_data = self.X_test.iloc[sample_idx]
            actual_label = self.y_test.iloc[sample_idx]
            print(f"Using sample {sample_idx} from test set.")
            print(f"Actual dropout status: {'Yes' if actual_label == 'Dropout' else 'No'}")

        # Make predictions with all available models
        predictions = {}

        for model_name, model in self.models.items():
            start_time = time.time()

            if model_name == 'lstm' and hasattr(self, 'temporal_X_test'):
                # For LSTM, reshape the data
                sample_data = self.temporal_X_test[sample_idx:sample_idx+1]
                pred_prob = model.predict(sample_data)[0][0]
            else:
                # For other models
                if isinstance(student_data, pd.Series):
                    sample_data = student_data.values.reshape(1, -1)
                else:
                    sample_data = student_data.reshape(1, -1)

                pred_prob = model.predict_proba(sample_data)[0][1]

            execution_time = time.time() - start_time

            risk_level = "High" if pred_prob >= 0.7 else "Medium" if pred_prob >= 0.4 else "Low"

            predictions[model_name] = {
                'probability': pred_prob,
                'risk_level': risk_level,
                'execution_time': execution_time
            }

        # Display predictions
        print("\nDropout Risk Predictions")
        print("------------------------")

        pred_df = pd.DataFrame({
            'Model': list(predictions.keys()),
            'Dropout Probability': [pred['probability'] for pred in predictions.values()],
            'Risk Level': [pred['risk_level'] for pred in predictions.values()],
            'Execution Time (s)': [pred['execution_time'] for pred in predictions.values()]
        })

        display(pred_df)

        # Visualize predictions
        plt.figure(figsize=(10, 6))
        bars = plt.barh(pred_df['Model'], pred_df['Dropout Probability'], color=['green' if p < 0.4 else 'orange' if p < 0.7 else 'red' for p in pred_df['Dropout Probability']])

        plt.title('Dropout Risk Probability by Model')
        plt.xlabel('Probability')
        plt.xlim(0, 1)

        # Add threshold lines
        plt.axvline(x=0.4, color='orange', linestyle='--', alpha=0.7, label='Medium Risk Threshold')
        plt.axvline(x=0.7, color='red', linestyle='--', alpha=0.7, label='High Risk Threshold')

        # Add probability values on bars
        for bar, prob in zip(bars, pred_df['Dropout Probability']):
            plt.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2, f'{prob:.2f}', va='center')

        plt.legend()
        plt.tight_layout()
        plt.show()

        # If XGBoost is available and used for prediction, provide SHAP explanation
        if 'xgboost' in self.models and self.explainer is not None:
            print("\nExplanation for XGBoost prediction:")

            # Calculate SHAP values
            if isinstance(student_data, pd.Series):
                explanation = self.explainer.shap_values(student_data.values.reshape(1, -1))[0]
            else:
                explanation = self.explainer.shap_values(student_data.reshape(1, -1))[0]

            # Plot explanation
            plt.figure(figsize=(12, 6))
            shap.force_plot(
                base_value=self.explainer.expected_value,
                shap_values=explanation,
                features=student_data,
                feature_names=self.X_test.columns,
                matplotlib=True,
                show=False
            )
            plt.title('Factors Influencing Dropout Prediction')
            plt.tight_layout()
            plt.show()

            # Provide actionable insights
            feature_impact = pd.DataFrame({
                'Feature': self.X_test.columns,
                'Impact': explanation
            }).sort_values('Impact', ascending=False)

            # Top positive factors (increasing dropout risk)
            positive_factors = feature_impact[feature_impact['Impact'] > 0].head(5)

            # Top negative factors (decreasing dropout risk)
            negative_factors = feature_impact[feature_impact['Impact'] < 0].head(5)

            print("\nActionable Insights:")
            print("-------------------")

            if not positive_factors.empty:
                print("Top risk factors to address:")
                for i, (feature, impact) in enumerate(zip(positive_factors['Feature'], positive_factors['Impact']), 1):
                    print(f"{i}. {feature}: Contributes {impact:.4f} to dropout risk")

            if not negative_factors.empty:
                print("\nProtective factors to maintain:")
                for i, (feature, impact) in enumerate(zip(negative_factors['Feature'], negative_factors['Impact']), 1):
                    print(f"{i}. {feature}: Reduces dropout risk by {abs(impact):.4f}")

            print("\nRecommendations:")
            print("For high-risk students, consider:")
            print("1. Academic interventions targeting specific subjects")
            print("2. Increased advisor check-ins")
            print("3. Connecting to support services")
            print("4. Peer mentoring programs")
            print("5. Financial aid review if applicable")

# Main execution
if __name__ == "__main__":
    print("Student Dropout Prediction System")
    print("================================")
    print("This system uses advanced machine learning techniques to predict student dropout risk.")

    # Load dataset
    file_path = input("Please enter the path to your CSV dataset: ")
    predictor = StudentDropoutPredictor()

    if predictor.load_data(file_path):
        if predictor.preprocess_data(target_col='Target'):
            # Train models
            predictor.train_baseline_model()
            predictor.train_xgboost_model(optimize=True)
            predictor.train_lstm_model()
            # Compare models
            predictor.compare_models()
            # Predict dropout risk for a sample
            predictor.predict_dropout_risk()
        else:
            print("Data preprocessing failed.")
    else:
        print("Failed to load dataset.")

# Student Dropout Prediction System
# Advanced implementation with XGBoost, LSTM, SMOTE, SHAP and Bayesian Optimization

# Install required packages
!pip install xgboost shap imbalanced-learn scikit-optimize matplotlib seaborn tensorflow pandas numpy scikit-learn yellowbrick

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from sklearn.linear_model import LogisticRegression
import xgboost as xgb
from imblearn.over_sampling import SMOTE
import shap
from skopt import BayesSearchCV
from skopt.space import Real, Integer
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout
from tensorflow.keras.callbacks import EarlyStopping
import io
import time
import warnings
warnings.filterwarnings('ignore')

# Define the main class for the Student Dropout Prediction System
class StudentDropoutPredictor:
    def __init__(self):
        self.data = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.X_train_resampled = None
        self.y_train_resampled = None
        self.models = {}
        self.results = {}
        self.temporal_features = []
        self.scaler = StandardScaler()
        self.le = LabelEncoder()
        self.explainer = None
        self.semester_columns = []
        self.lstm_model = None
        self.current_model = None

    def load_data(self, file_path):
        """Load the dataset from the specified file path"""
        try:
            # Load the data based on the file extension
            if file_path.endswith('.csv'):
                self.data = pd.read_csv(file_path)
            elif file_path.endswith(('.xls', '.xlsx')):
                self.data = pd.read_excel(file_path)
            else:
                raise ValueError("Unsupported file format. Please upload a CSV or Excel file.")

            # Display data info
            print(f"Dataset loaded successfully. Shape: {self.data.shape}")
            print("\nData Sample:")
            display(self.data.head())
            print("\nData Info:")
            self.data.info()
            print("\nSummary Statistics:")
            display(self.data.describe())
            print("\nMissing Values:")
            display(self.data.isnull().sum())

            # Check for class imbalance
            if 'Target' in self.data.columns:  # Adjusted to match your dataset
                target_col = 'Target'
            else:
                print("Warning: Could not identify target column. Please rename your target column to 'Target'.")
                return

            # Convert target to binary
            self.data[target_col] = self.data[target_col].map({'Dropout': 1, 'Graduate': 0})

            # Class distribution
            class_counts = self.data[target_col].value_counts()
            dropout_rate = class_counts.get(1, 0) / len(self.data) * 100
            print(f"\nClass Distribution:\n{class_counts}")
            print(f"Dropout Rate: {dropout_rate:.2f}%")

            # Visualize class distribution
            plt.figure(figsize=(8, 6))
            sns.countplot(x=target_col, data=self.data)
            plt.title('Class Distribution')
            plt.ylabel('Count')
            plt.xlabel('Dropout (1 = Yes, 0 = No)')
            plt.show()

            return True
        except Exception as e:
            print(f"Error loading data: {str(e)}")
            return False

    def preprocess_data(self, test_size=0.2, random_state=42, target_col='Target'):
        """Preprocess the data for model training"""
        try:
            # If target column is not 'Target', check for alternatives
            if target_col not in self.data.columns:
                print("Warning: Target column not found. Please specify the correct target column name.")
                return False

            # Separate features and target
            X = self.data.drop(columns=[target_col])
            y = self.data[target_col]

            # Handle categorical variables
            categorical_cols = X.select_dtypes(include=['object', 'category']).columns
            for col in categorical_cols:
                X[col] = self.le.fit_transform(X[col])

            # Split the data
            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
                X, y, test_size=test_size, random_state=random_state, stratify=y
            )

            # Scale the features
            self.X_train = pd.DataFrame(
                self.scaler.fit_transform(self.X_train),
                columns=X.columns
            )
            self.X_test = pd.DataFrame(
                self.scaler.transform(self.X_test),
                columns=X.columns
            )

            # Apply SMOTE to handle class imbalance
            smote = SMOTE(random_state=random_state)
            self.X_train_resampled, self.y_train_resampled = smote.fit_resample(self.X_train, self.y_train)

            print("Data preprocessing completed successfully.")
            print(f"Original training set shape: {self.X_train.shape}, Class distribution: {pd.Series(self.y_train).value_counts()}")
            print(f"Resampled training set shape: {self.X_train_resampled.shape}, Class distribution: {pd.Series(self.y_train_resampled).value_counts()}")

            return True
        except Exception as e:
            print(f"Error preprocessing data: {str(e)}")
            return False

    def train_baseline_model(self):
        """Train the baseline Logistic Regression model"""
        start_time = time.time()
        print("Training Logistic Regression baseline model...")

        # Create and train the model
        lr_model = LogisticRegression(max_iter=1000, random_state=42)
        lr_model.fit(self.X_train, self.y_train)

        # Make predictions
        y_pred = lr_model.predict(self.X_test)

        # Evaluate the model
        report = classification_report(self.y_test, y_pred, output_dict=True)
        cm = confusion_matrix(self.y_test, y_pred)

        # Calculate ROC curve
        y_pred_proba = lr_model.predict_proba(self.X_test)[:, 1]
        fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)

        execution_time = time.time() - start_time

        # Store results
        self.models['logistic_regression'] = lr_model
        self.results['logistic_regression'] = {
            'report': report,
            'confusion_matrix': cm,
            'execution_time': execution_time,
            'roc_auc': roc_auc,
            'fpr': fpr,
            'tpr': tpr
        }

        print(f"Baseline Logistic Regression model trained in {execution_time:.3f} seconds")
        print(f"Test set accuracy: {report['accuracy']:.4f}")
        print(f"ROC AUC: {roc_auc:.4f}")
        print("Classification Report:")
        print(classification_report(self.y_test, y_pred))

        # Plot confusion matrix
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Not Dropout', 'Dropout'],
                    yticklabels=['Not Dropout', 'Dropout'])
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title('Confusion Matrix - Logistic Regression')
        plt.show()

    def train_xgboost_model(self, optimize=True):
        """Train the XGBoost model with optional Bayesian optimization"""
        start_time = time.time()
        print("Training XGBoost model...")

        if optimize:
            print("Using Bayesian optimization to find optimal hyperparameters...")

            # Define the search space
            search_spaces = {
                'learning_rate': Real(0.01, 0.3),
                'max_depth': Integer(3, 10),
                'min_child_weight': Integer(1, 10),
                'gamma': Real(0, 1),
                'subsample': Real(0.5, 1.0),
                'colsample_bytree': Real(0.5, 1.0),
                'n_estimators': Integer(50, 300)
            }

            # Create the XGBoost model
            xgb_model = xgb.XGBClassifier(
                objective='binary:logistic',
                random_state=42,
                use_label_encoder=False,
                eval_metric='logloss'
            )

            # Perform Bayesian optimization
            bayes_search = BayesSearchCV(
                xgb_model,
                search_spaces,
                n_iter=10,  # Reduced for faster execution
                cv=3,        # Reduced for faster execution
                n_jobs=-1,
                random_state=42,
                scoring='roc_auc'
            )

            bayes_search.fit(self.X_train_resampled, self.y_train_resampled)

            # Get the best model
            xgb_model = bayes_search.best_estimator_
            print(f"Best hyperparameters: {bayes_search.best_params_}")
        else:
            # Use default hyperparameters
            xgb_model = xgb.XGBClassifier(
                objective='binary:logistic',
                random_state=42,
                use_label_encoder=False,
                eval_metric='logloss'
            )
            xgb_model.fit(self.X_train_resampled, self.y_train_resampled)

        # Make predictions
        y_pred = xgb_model.predict(self.X_test)

        # Evaluate the model
        report = classification_report(self.y_test, y_pred, output_dict=True)
        cm = confusion_matrix(self.y_test, y_pred)

        # Calculate ROC curve
        y_pred_proba = xgb_model.predict_proba(self.X_test)[:, 1]
        fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)

        execution_time = time.time() - start_time

        # Store results
        self.models['xgboost'] = xgb_model
        self.results['xgboost'] = {
            'report': report,
            'confusion_matrix': cm,
            'execution_time': execution_time,
            'roc_auc': roc_auc,
            'fpr': fpr,
            'tpr': tpr
        }

        # Create SHAP explainer
        self.explainer = shap.TreeExplainer(xgb_model)

        print(f"XGBoost model trained in {execution_time:.3f} seconds")
        print(f"Test set accuracy: {report['accuracy']:.4f}")
        print(f"ROC AUC: {roc_auc:.4f}")
        print("Classification Report:")
        print(classification_report(self.y_test, y_pred))

        # Plot confusion matrix
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Not Dropout', 'Dropout'],
                    yticklabels=['Not Dropout', 'Dropout'])
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title('Confusion Matrix - XGBoost')
        plt.show()

        # Set as current model
        self.current_model = 'xgboost'

    def train_lstm_model(self):
        """Train the LSTM model for temporal data"""
        if not hasattr(self, 'temporal_X_train') or self.temporal_X_train is None or len(self.temporal_X_train) == 0:
            print("No temporal data available for LSTM. Run preprocess_data with temporal=True first.")
            return

        start_time = time.time()
        print("Training LSTM model...")

        # Define the LSTM model architecture
        self.lstm_model = Sequential([
            LSTM(64, input_shape=(self.temporal_X_train.shape[1], self.temporal_X_train.shape[2]), return_sequences=True),
            Dropout(0.2),
            LSTM(32),
            Dropout(0.2),
            Dense(16, activation='relu'),
            Dense(1, activation='sigmoid')
        ])

        # Compile the model
        self.lstm_model.compile(
            optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy']
        )

        # Early stopping to prevent overfitting
        early_stopping = EarlyStopping(
            monitor='val_loss',
            patience=5,
            restore_best_weights=True
        )

        # Train the model
        history = self.lstm_model.fit(
            self.temporal_X_train, self.y_train_resampled,
            epochs=20,
            batch_size=32,
            validation_split=0.2,
            callbacks=[early_stopping],
            verbose=1
        )

        # Make predictions
        y_pred_proba = self.lstm_model.predict(self.temporal_X_test)
        y_pred = (y_pred_proba > 0.5).astype(int).flatten()

        # Evaluate the model
        report = classification_report(self.y_test, y_pred, output_dict=True)
        cm = confusion_matrix(self.y_test, y_pred)

        # Calculate ROC curve
        fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)

        execution_time = time.time() - start_time

        # Store results
        self.models['lstm'] = self.lstm_model
        self.results['lstm'] = {
            'report': report,
            'confusion_matrix': cm,
            'execution_time': execution_time,
            'roc_auc': roc_auc,
            'fpr': fpr,
            'tpr': tpr,
            'history': history.history
        }

        print(f"LSTM model trained in {execution_time:.3f} seconds")
        print(f"Test set accuracy: {report['accuracy']:.4f}")
        print(f"ROC AUC: {roc_auc:.4f}")
        print("Classification Report:")
        print(classification_report(self.y_test, y_pred))

        # Plot confusion matrix
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Not Dropout', 'Dropout'],
                    yticklabels=['Not Dropout', 'Dropout'])
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title('Confusion Matrix - LSTM')
        plt.show()

        # Plot training history
        plt.figure(figsize=(12, 5))
        plt.subplot(1, 2, 1)
        plt.plot(history.history['accuracy'])
        plt.plot(history.history['val_accuracy'])
        plt.title('Model Accuracy')
        plt.ylabel('Accuracy')
        plt.xlabel('Epoch')
        plt.legend(['Train', 'Validation'], loc='lower right')

        plt.subplot(1, 2, 2)
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('Model Loss')
        plt.ylabel('Loss')
        plt.xlabel('Epoch')
        plt.legend(['Train', 'Validation'], loc='upper right')
        plt.tight_layout()
        plt.show()

        # Set as current model
        self.current_model = 'lstm'

    def compare_models(self):
        """Compare all trained models"""
        if not self.results:
            print("No models trained yet. Please train at least one model first.")
            return

        print("Model Comparison")
        print("---------------")

        # Create comparison table
        comparison = {
            'Model': [],
            'Accuracy': [],
            'Precision (Dropout)': [],
            'Recall (Dropout)': [],
            'F1-Score (Dropout)': [],
            'ROC AUC': [],
            'Execution Time (s)': []
        }

        # Collect results for each model
        for model_name, result in self.results.items():
            comparison['Model'].append(model_name)
            comparison['Accuracy'].append(result['report']['accuracy'])
            comparison['Precision (Dropout)'].append(result['report']['1']['precision'])
            comparison['Recall (Dropout)'].append(result['report']['1']['recall'])
            comparison['F1-Score (Dropout)'].append(result['report']['1']['f1-score'])
            comparison['ROC AUC'].append(result['roc_auc'])
            comparison['Execution Time (s)'].append(result['execution_time'])

        # Display comparison table
        comparison_df = pd.DataFrame(comparison)
        display(comparison_df)

        # Plot ROC curves for all models
        plt.figure(figsize=(10, 8))

        for model_name, result in self.results.items():
            plt.plot(result['fpr'], result['tpr'], label=f'{model_name} (AUC = {result["roc_auc"]:.4f})')

        plt.plot([0, 1], [0, 1], 'k--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('ROC Curves for all Models')
        plt.legend(loc="lower right")
        plt.show()

        # Bar chart comparing key metrics
        plt.figure(figsize=(12, 6))

        metrics = ['Accuracy', 'Precision (Dropout)', 'Recall (Dropout)', 'F1-Score (Dropout)']
        x = np.arange(len(metrics))
        width = 0.2
        multiplier = 0

        for model_name, result in self.results.items():
            offset = width * multiplier
            values = [
                result['report']['accuracy'],
                result['report']['1']['precision'],
                result['report']['1']['recall'],
                result['report']['1']['f1-score']
            ]

            plt.bar(x + offset, values, width, label=model_name)
            multiplier += 1

        plt.ylabel('Score')
        plt.title('Performance Comparison')
        plt.xticks(x + width, metrics)
        plt.legend(loc='upper left')
        plt.ylim(0, 1)
        plt.tight_layout()
        plt.show()

    def explain_predictions(self, num_samples=5):
        """Explain model predictions using SHAP values"""
        if self.current_model != 'xgboost' or 'xgboost' not in self.models:
            print("SHAP explanation is currently only available for XGBoost models.")
            print("Please train an XGBoost model first.")
            return

        print("Generating SHAP explanations for model predictions...")

        # Calculate SHAP values for the test set
        shap_values = self.explainer.shap_values(self.X_test)

        # Summary plot
        plt.figure(figsize=(10, 8))
        shap.summary_plot(shap_values, self.X_test, plot_type="bar", show=False)
        plt.title("Feature Importance Based on SHAP Values")
        plt.tight_layout()
        plt.show()

        # Detailed summary plot
        plt.figure(figsize=(12, 10))
        shap.summary_plot(shap_values, self.X_test, show=False)
        plt.title("Feature Impact on Predictions")
        plt.tight_layout()
        plt.show()

        # Individual explanations for a few samples
        print(f"\nDetailed explanations for {num_samples} sample predictions:")

        for i in range(min(num_samples, len(self.X_test))):
            plt.figure(figsize=(12, 6))

            # Get actual and predicted values
            actual = self.y_test.iloc[i]
            prediction = self.models['xgboost'].predict_proba([self.X_test.iloc[i]])[0][1]

            # Create force plot
            shap.force_plot(
                base_value=self.explainer.expected_value,
                shap_values=shap_values[i],
                features=self.X_test.iloc[i],
                feature_names=self.X_test.columns,
                matplotlib=True,
                show=False
            )

            plt.title(f"Sample {i+1}: Actual={actual}, Predicted Probability={prediction:.4f}")
            plt.tight_layout()
            plt.show()

            # Print top 5 contributing features
            feature_importance = pd.DataFrame({
                'Feature': self.X_test.columns,
                'Importance': np.abs(shap_values[i])
            }).sort_values('Importance', ascending=False).head(5)

            print(f"Top contributing features for Sample {i+1}:")
            display(feature_importance)
            print("\n" + "-"*50 + "\n")

    def predict_dropout_risk(self, student_data=None):
        """Predict dropout risk for a single student or a sample from test set"""
        if not self.models:
            print("No models trained yet. Please train at least one model first.")
            return

        if student_data is None:
            # Use a sample from the test set
            sample_idx = np.random.choice(len(self.X_test))
            student_data = self.X_test.iloc[sample_idx]
            actual_label = self.y_test.iloc[sample_idx]
            print(f"Using sample {sample_idx} from test set.")
            print(f"Actual dropout status: {'Yes' if actual_label == 1 else 'No'}")

        # Make predictions with all available models
        predictions = {}

        for model_name, model in self.models.items():
            start_time = time.time()

            if model_name == 'lstm' and hasattr(self, 'temporal_X_test'):
                # For LSTM, reshape the data
                sample_data = self.temporal_X_test[sample_idx:sample_idx+1]
                pred_prob = model.predict(sample_data)[0][0]
            else:
                # For other models
                if isinstance(student_data, pd.Series):
                    sample_data = student_data.values.reshape(1, -1)
                else:
                    sample_data = student_data.reshape(1, -1)

                pred_prob = model.predict_proba(sample_data)[0][1]

            execution_time = time.time() - start_time

            risk_level = "High" if pred_prob >= 0.7 else "Medium" if pred_prob >= 0.4 else "Low"

            predictions[model_name] = {
                'probability': pred_prob,
                'risk_level': risk_level,
                'execution_time': execution_time
            }

        # Display predictions
        print("\nDropout Risk Predictions")
        print("------------------------")

        pred_df = pd.DataFrame({
            'Model': list(predictions.keys()),
            'Dropout Probability': [pred['probability'] for pred in predictions.values()],
            'Risk Level': [pred['risk_level'] for pred in predictions.values()],
            'Execution Time (s)': [pred['execution_time'] for pred in predictions.values()]
        })

        display(pred_df)

        # Visualize predictions
        plt.figure(figsize=(10, 6))
        bars = plt.barh(pred_df['Model'], pred_df['Dropout Probability'], color=['green' if p < 0.4 else 'orange' if p < 0.7 else 'red' for p in pred_df['Dropout Probability']])

        plt.title('Dropout Risk Probability by Model')
        plt.xlabel('Probability')
        plt.xlim(0, 1)

        # Add threshold lines
        plt.axvline(x=0.4, color='orange', linestyle='--', alpha=0.7, label='Medium Risk Threshold')
        plt.axvline(x=0.7, color='red', linestyle='--', alpha=0.7, label='High Risk Threshold')

        # Add probability values on bars
        for bar, prob in zip(bars, pred_df['Dropout Probability']):
            plt.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2, f'{prob:.2f}', va='center')

        plt.legend()
        plt.tight_layout()
        plt.show()

        # If XGBoost is available and used for prediction, provide SHAP explanation
        if 'xgboost' in self.models and self.explainer is not None:
            print("\nExplanation for XGBoost prediction:")

            # Calculate SHAP values
            if isinstance(student_data, pd.Series):
                explanation = self.explainer.shap_values(student_data.values.reshape(1, -1))[0]
            else:
                explanation = self.explainer.shap_values(student_data.reshape(1, -1))[0]

            # Plot explanation
            plt.figure(figsize=(12, 6))
            shap.force_plot(
                base_value=self.explainer.expected_value,
                shap_values=explanation,
                features=student_data,
                feature_names=self.X_test.columns,
                matplotlib=True,
                show=False
            )
            plt.title('Factors Influencing Dropout Prediction')
            plt.tight_layout()
            plt.show()

            # Provide actionable insights
            feature_impact = pd.DataFrame({
                'Feature': self.X_test.columns,
                'Impact': explanation
            }).sort_values('Impact', ascending=False)

            # Top positive factors (increasing dropout risk)
            positive_factors = feature_impact[feature_impact['Impact'] > 0].head(5)

            # Top negative factors (decreasing dropout risk)
            negative_factors = feature_impact[feature_impact['Impact'] < 0].head(5)

            print("\nActionable Insights:")
            print("-------------------")

            if not positive_factors.empty:
                print("Top risk factors to address:")
                for i, (feature, impact) in enumerate(zip(positive_factors['Feature'], positive_factors['Impact']), 1):
                    print(f"{i}. {feature}: Contributes {impact:.4f} to dropout risk")

            if not negative_factors.empty:
                print("\nProtective factors to maintain:")
                for i, (feature, impact) in enumerate(zip(negative_factors['Feature'], negative_factors['Impact']), 1):
                    print(f"{i}. {feature}: Reduces dropout risk by {abs(impact):.4f}")

            print("\nRecommendations:")
            print("For high-risk students, consider:")
            print("1. Academic interventions targeting specific subjects")
            print("2. Increased advisor check-ins")
            print("3. Connecting to support services")
            print("4. Peer mentoring programs")
            print("5. Financial aid review if applicable")

# Main execution
if __name__ == "__main__":
    print("Student Dropout Prediction System")
    print("================================")
    print("This system uses advanced machine learning techniques to predict student dropout risk.")

    # Load dataset
    file_path = input("Please enter the path to your CSV dataset: ")
    predictor = StudentDropoutPredictor()

    if predictor.load_data(file_path):
        if predictor.preprocess_data(target_col='Target'):
            # Train models
            predictor.train_baseline_model()
            predictor.train_xgboost_model(optimize=True)
            predictor.train_lstm_model()
            # Compare models
            predictor.compare_models()
            # Predict dropout risk for a sample
            predictor.predict_dropout_risk()
        else:
            print("Data preprocessing failed.")
    else:
        print("Failed to load dataset.")

# Student Dropout Prediction System
# Advanced implementation with XGBoost, LSTM, SMOTE, SHAP and Bayesian Optimization

# Install required packages
!pip install xgboost shap imbalanced-learn scikit-optimize matplotlib seaborn tensorflow pandas numpy scikit-learn yellowbrick

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from sklearn.linear_model import LogisticRegression
import xgboost as xgb
from imblearn.over_sampling import SMOTE
import shap
from skopt import BayesSearchCV
from skopt.space import Real, Integer
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout
from tensorflow.keras.callbacks import EarlyStopping
import io
import time
import warnings
warnings.filterwarnings('ignore')

# Define the main class for the Student Dropout Prediction System
class StudentDropoutPredictor:
    def __init__(self):
        self.data = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.X_train_resampled = None
        self.y_train_resampled = None
        self.models = {}
        self.results = {}
        self.temporal_features = []
        self.scaler = StandardScaler()
        self.le = LabelEncoder()
        self.explainer = None
        self.lstm_model = None
        self.current_model = None

    def load_data(self, file_path):
        """Load the dataset from the specified file path"""
        try:
            # Load the data based on the file extension
            if file_path.endswith('.csv'):
                self.data = pd.read_csv(file_path)
            elif file_path.endswith(('.xls', '.xlsx')):
                self.data = pd.read_excel(file_path)
            else:
                raise ValueError("Unsupported file format. Please upload a CSV or Excel file.")

            # Display data info
            print(f"Dataset loaded successfully. Shape: {self.data.shape}")
            print("\nData Sample:")
            display(self.data.head())
            print("\nData Info:")
            self.data.info()
            print("\nSummary Statistics:")
            display(self.data.describe())
            print("\nMissing Values:")
            display(self.data.isnull().sum())

            # Check for class imbalance
            if 'Target' in self.data.columns:  # Adjusted to match your dataset
                target_col = 'Target'
            else:
                print("Warning: Could not identify target column. Please rename your target column to 'Target'.")
                return

            # Convert target to binary
            self.data[target_col] = self.data[target_col].map({'Dropout': 1, 'Graduate': 0})

            # Drop rows with NaN values in the target column
            self.data.dropna(subset=[target_col], inplace=True)

            # Class distribution
            class_counts = self.data[target_col].value_counts()
            dropout_rate = class_counts.get(1, 0) / len(self.data) * 100
            print(f"\nClass Distribution:\n{class_counts}")
            print(f"Dropout Rate: {dropout_rate:.2f}%")

            # Visualize class distribution
            plt.figure(figsize=(8, 6))
            sns.countplot(x=target_col, data=self.data)
            plt.title('Class Distribution')
            plt.ylabel('Count')
            plt.xlabel('Dropout (1 = Yes, 0 = No)')
            plt.show()

            return True
        except Exception as e:
            print(f"Error loading data: {str(e)}")
            return False

    def preprocess_data(self, test_size=0.2, random_state=42, target_col='Target'):
        """Preprocess the data for model training"""
        try:
            # If target column is not 'Target', check for alternatives
            if target_col not in self.data.columns:
                print("Warning: Target column not found. Please specify the correct target column name.")
                return False

            # Separate features and target
            X = self.data.drop(columns=[target_col])
            y = self.data[target_col]

            # Handle categorical variables
            categorical_cols = X.select_dtypes(include=['object', 'category']).columns
            for col in categorical_cols:
                X[col] = self.le.fit_transform(X[col])

            # Drop rows with NaN values in features
            X.dropna(inplace=True)
            y = y[X.index]  # Align target with features

            # Split the data
            self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
                X, y, test_size=test_size, random_state=random_state, stratify=y
            )

            # Scale the features
            self.X_train = pd.DataFrame(
                self.scaler.fit_transform(self.X_train),
                columns=X.columns
            )
            self.X_test = pd.DataFrame(
                self.scaler.transform(self.X_test),
                columns=X.columns
            )

            # Apply SMOTE to handle class imbalance
            smote = SMOTE(random_state=random_state)
            self.X_train_resampled, self.y_train_resampled = smote.fit_resample(self.X_train, self.y_train)

            print("Data preprocessing completed successfully.")
            print(f"Original training set shape: {self.X_train.shape}, Class distribution: {pd.Series(self.y_train).value_counts()}")
            print(f"Resampled training set shape: {self.X_train_resampled.shape}, Class distribution: {pd.Series(self.y_train_resampled).value_counts()}")

            return True
        except Exception as e:
            print(f"Error preprocessing data: {str(e)}")
            return False

    def train_baseline_model(self):
        """Train the baseline Logistic Regression model"""
        start_time = time.time()
        print("Training Logistic Regression baseline model...")

        # Create and train the model
        lr_model = LogisticRegression(max_iter=1000, random_state=42)
        lr_model.fit(self.X_train, self.y_train)

        # Make predictions
        y_pred = lr_model.predict(self.X_test)

        # Evaluate the model
        report = classification_report(self.y_test, y_pred, output_dict=True)
        cm = confusion_matrix(self.y_test, y_pred)

        # Calculate ROC curve
        y_pred_proba = lr_model.predict_proba(self.X_test)[:, 1]
        fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)

        execution_time = time.time() - start_time

        # Store results
        self.models['logistic_regression'] = lr_model
        self.results['logistic_regression'] = {
            'report': report,
            'confusion_matrix': cm,
            'execution_time': execution_time,
            'roc_auc': roc_auc,
            'fpr': fpr,
            'tpr': tpr
        }

        print(f"Baseline Logistic Regression model trained in {execution_time:.3f} seconds")
        print(f"Test set accuracy: {report['accuracy']:.4f}")
        print(f"ROC AUC: {roc_auc:.4f}")
        print("Classification Report:")
        print(classification_report(self.y_test, y_pred))

        # Plot confusion matrix
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Not Dropout', 'Dropout'],
                    yticklabels=['Not Dropout', 'Dropout'])
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title('Confusion Matrix - Logistic Regression')
        plt.show()

    def train_xgboost_model(self, optimize=True):
        """Train the XGBoost model with optional Bayesian optimization"""
        start_time = time.time()
        print("Training XGBoost model...")

        if optimize:
            print("Using Bayesian optimization to find optimal hyperparameters...")

            # Define the search space
            search_spaces = {
                'learning_rate': Real(0.01, 0.3),
                'max_depth': Integer(3, 10),
                'min_child_weight': Integer(1, 10),
                'gamma': Real(0, 1),
                'subsample': Real(0.5, 1.0),
                'colsample_bytree': Real(0.5, 1.0),
                'n_estimators': Integer(50, 300)
            }

            # Create the XGBoost model
            xgb_model = xgb.XGBClassifier(
                objective='binary:logistic',
                random_state=42,
                use_label_encoder=False,
                eval_metric='logloss'
            )

            # Perform Bayesian optimization
            bayes_search = BayesSearchCV(
                xgb_model,
                search_spaces,
                n_iter=10,  # Reduced for faster execution
                cv=3,        # Reduced for faster execution
                n_jobs=-1,
                random_state=42,
                scoring='roc_auc'
            )

            bayes_search.fit(self.X_train_resampled, self.y_train_resampled)

            # Get the best model
            xgb_model = bayes_search.best_estimator_
            print(f"Best hyperparameters: {bayes_search.best_params_}")
        else:
            # Use default hyperparameters
            xgb_model = xgb.XGBClassifier(
                objective='binary:logistic',
                random_state=42,
                use_label_encoder=False,
                eval_metric='logloss'
            )
            xgb_model.fit(self.X_train_resampled, self.y_train_resampled)

        # Make predictions
        y_pred = xgb_model.predict(self.X_test)

        # Evaluate the model
        report = classification_report(self.y_test, y_pred, output_dict=True)
        cm = confusion_matrix(self.y_test, y_pred)

        # Calculate ROC curve
        y_pred_proba = xgb_model.predict_proba(self.X_test)[:, 1]
        fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)

        execution_time = time.time() - start_time

        # Store results
        self.models['xgboost'] = xgb_model
        self.results['xgboost'] = {
            'report': report,
            'confusion_matrix': cm,
            'execution_time': execution_time,
            'roc_auc': roc_auc,
            'fpr': fpr,
            'tpr': tpr
        }

        # Create SHAP explainer
        self.explainer = shap.TreeExplainer(xgb_model)

        print(f"XGBoost model trained in {execution_time:.3f} seconds")
        print(f"Test set accuracy: {report['accuracy']:.4f}")
        print(f"ROC AUC: {roc_auc:.4f}")
        print("Classification Report:")
        print(classification_report(self.y_test, y_pred))

        # Plot confusion matrix
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Not Dropout', 'Dropout'],
                    yticklabels=['Not Dropout', 'Dropout'])
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title('Confusion Matrix - XGBoost')
        plt.show()

        # Set as current model
        self.current_model = 'xgboost'

    def train_lstm_model(self):
        """Train the LSTM model for temporal data"""
        if not hasattr(self, 'temporal_X_train') or self.temporal_X_train is None or len(self.temporal_X_train) == 0:
            print("No temporal data available for LSTM. Run preprocess_data with temporal=True first.")
            return

        start_time = time.time()
        print("Training LSTM model...")

        # Define the LSTM model architecture
        self.lstm_model = Sequential([
            LSTM(64, input_shape=(self.temporal_X_train.shape[1], self.temporal_X_train.shape[2]), return_sequences=True),
            Dropout(0.2),
            LSTM(32),
            Dropout(0.2),
            Dense(16, activation='relu'),
            Dense(1, activation='sigmoid')
        ])

        # Compile the model
        self.lstm_model.compile(
            optimizer='adam',
            loss='binary_crossentropy',
            metrics=['accuracy']
        )

        # Early stopping to prevent overfitting
        early_stopping = EarlyStopping(
            monitor='val_loss',
            patience=5,
            restore_best_weights=True
        )

        # Train the model
        history = self.lstm_model.fit(
            self.temporal_X_train, self.y_train_resampled,
            epochs=20,
            batch_size=32,
            validation_split=0.2,
            callbacks=[early_stopping],
            verbose=1
        )

        # Make predictions
        y_pred_proba = self.lstm_model.predict(self.temporal_X_test)
        y_pred = (y_pred_proba > 0.5).astype(int).flatten()

        # Evaluate the model
        report = classification_report(self.y_test, y_pred, output_dict=True)
        cm = confusion_matrix(self.y_test, y_pred)

        # Calculate ROC curve
        fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)

        execution_time = time.time() - start_time

        # Store results
        self.models['lstm'] = self.lstm_model
        self.results['lstm'] = {
            'report': report,
            'confusion_matrix': cm,
            'execution_time': execution_time,
            'roc_auc': roc_auc,
            'fpr': fpr,
            'tpr': tpr,
            'history': history.history
        }

        print(f"LSTM model trained in {execution_time:.3f} seconds")
        print(f"Test set accuracy: {report['accuracy']:.4f}")
        print(f"ROC AUC: {roc_auc:.4f}")
        print("Classification Report:")
        print(classification_report(self.y_test, y_pred))

        # Plot confusion matrix
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['Not Dropout', 'Dropout'],
                    yticklabels=['Not Dropout', 'Dropout'])
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title('Confusion Matrix - LSTM')
        plt.show()

        # Plot training history
        plt.figure(figsize=(12, 5))
        plt.subplot(1, 2, 1)
        plt.plot(history.history['accuracy'])
        plt.plot(history.history['val_accuracy'])
        plt.title('Model Accuracy')
        plt.ylabel('Accuracy')
        plt.xlabel('Epoch')
        plt.legend(['Train', 'Validation'], loc='lower right')

        plt.subplot(1, 2, 2)
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('Model Loss')
        plt.ylabel('Loss')
        plt.xlabel('Epoch')
        plt.legend(['Train', 'Validation'], loc='upper right')
        plt.tight_layout()
        plt.show()

        # Set as current model
        self.current_model = 'lstm'

    def compare_models(self):
        """Compare all trained models"""
        if not self.results:
            print("No models trained yet. Please train at least one model first.")
            return

        print("Model Comparison")
        print("---------------")

        # Create comparison table
        comparison = {
            'Model': [],
            'Accuracy': [],
            'Precision (Dropout)': [],
            'Recall (Dropout)': [],
            'F1-Score (Dropout)': [],
            'ROC AUC': [],
            'Execution Time (s)': []
        }

        # Collect results for each model
        for model_name, result in self.results.items():
            comparison['Model'].append(model_name)
            comparison['Accuracy'].append(result['report']['accuracy'])
            # Check if the dropout class exists in the report
            if '1' in result['report']:
                comparison['Precision (Dropout)'].append(result['report']['1']['precision'])
                comparison['Recall (Dropout)'].append(result['report']['1']['recall'])
                comparison['F1-Score (Dropout)'].append(result['report']['1']['f1-score'])
            else:
                comparison['Precision (Dropout)'].append(0)
                comparison['Recall (Dropout)'].append(0)
                comparison['F1-Score (Dropout)'].append(0)
            comparison['ROC AUC'].append(result['roc_auc'])
            comparison['Execution Time (s)'].append(result['execution_time'])

        # Display comparison table
        comparison_df = pd.DataFrame(comparison)
        display(comparison_df)

        # Plot ROC curves for all models
        plt.figure(figsize=(10, 8))

        for model_name, result in self.results.items():
            plt.plot(result['fpr'], result['tpr'], label=f'{model_name} (AUC = {result["roc_auc"]:.4f})')

        plt.plot([0, 1], [0, 1], 'k--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('ROC Curves for all Models')
        plt.legend(loc="lower right")
        plt.show()

        # Bar chart comparing key metrics
        plt.figure(figsize=(12, 6))

        metrics = ['Accuracy', 'Precision (Dropout)', 'Recall (Dropout)', 'F1-Score (Dropout)']
        x = np.arange(len(metrics))
        width = 0.2
        multiplier = 0

        for model_name, result in self.results.items():
            offset = width * multiplier
            values = [
                result['report']['accuracy'],
                result['report']['1']['precision'] if '1' in result['report'] else 0,
                result['report']['1']['recall'] if '1' in result['report'] else 0,
                result['report']['1']['f1-score'] if '1' in result['report'] else 0
            ]

            plt.bar(x + offset, values, width, label=model_name)
            multiplier += 1

        plt.ylabel('Score')
        plt.title('Performance Comparison')
        plt.xticks(x + width, metrics)
        plt.legend(loc='upper left')
        plt.ylim(0, 1)
        plt.tight_layout()
        plt.show()

    def explain_predictions(self, num_samples=5):
        """Explain model predictions using SHAP values"""
        if self.current_model != 'xgboost' or 'xgboost' not in self.models:
            print("SHAP explanation is currently only available for XGBoost models.")
            print("Please train an XGBoost model first.")
            return

        print("Generating SHAP explanations for model predictions...")

        # Calculate SHAP values for the test set
        shap_values = self.explainer.shap_values(self.X_test)

        # Summary plot
        plt.figure(figsize=(10, 8))
        shap.summary_plot(shap_values, self.X_test, plot_type="bar", show=False)
        plt.title("Feature Importance Based on SHAP Values")
        plt.tight_layout()
        plt.show()

        # Detailed summary plot
        plt.figure(figsize=(12, 10))
        shap.summary_plot(shap_values, self.X_test, show=False)
        plt.title("Feature Impact on Predictions")
        plt.tight_layout()
        plt.show()

        # Individual explanations for a few samples
        print(f"\nDetailed explanations for {num_samples} sample predictions:")

        for i in range(min(num_samples, len(self.X_test))):
            plt.figure(figsize=(12, 6))

            # Get actual and predicted values
            actual = self.y_test.iloc[i]
            prediction = self.models['xgboost'].predict_proba([self.X_test.iloc[i]])[0][1]

            # Create force plot
            shap.force_plot(
                base_value=self.explainer.expected_value,
                shap_values=shap_values[i],
                features=self.X_test.iloc[i],
                feature_names=self.X_test.columns,
                matplotlib=True,
                show=False
            )

            plt.title(f"Sample {i+1}: Actual={actual}, Predicted Probability={prediction:.4f}")
            plt.tight_layout()
            plt.show()

            # Print top 5 contributing features
            feature_importance = pd.DataFrame({
                'Feature': self.X_test.columns,
                'Importance': np.abs(shap_values[i])
            }).sort_values('Importance', ascending=False).head(5)

            print(f"Top contributing features for Sample {i+1}:")
            display(feature_importance)
            print("\n" + "-"*50 + "\n")

    def predict_dropout_risk(self, student_data=None):
        """Predict dropout risk for a single student or a sample from test set"""
        if not self.models:
            print("No models trained yet. Please train at least one model first.")
            return

        if student_data is None:
            # Use a sample from the test set
            sample_idx = np.random.choice(len(self.X_test))
            student_data = self.X_test.iloc[sample_idx]
            actual_label = self.y_test.iloc[sample_idx]
            print(f"Using sample {sample_idx} from test set.")
            print(f"Actual dropout status: {'Yes' if actual_label == 1 else 'No'}")

        # Make predictions with all available models
        predictions = {}

        for model_name, model in self.models.items():
            start_time = time.time()

            if model_name == 'lstm' and hasattr(self, 'temporal_X_test'):
                # For LSTM, reshape the data
                sample_data = self.temporal_X_test[sample_idx:sample_idx+1]
                pred_prob = model.predict(sample_data)[0][0]
            else:
                # For other models
                if isinstance(student_data, pd.Series):
                    sample_data = student_data.values.reshape(1, -1)
                else:
                    sample_data = student_data.reshape(1, -1)

                pred_prob = model.predict_proba(sample_data)[0][1]

            execution_time = time.time() - start_time

            risk_level = "High" if pred_prob >= 0.7 else "Medium" if pred_prob >= 0.4 else "Low"

            predictions[model_name] = {
                'probability': pred_prob,
                'risk_level': risk_level,
                'execution_time': execution_time
            }

        # Display predictions
        print("\nDropout Risk Predictions")
        print("------------------------")

        pred_df = pd.DataFrame({
            'Model': list(predictions.keys()),
            'Dropout Probability': [pred['probability'] for pred in predictions.values()],
            'Risk Level': [pred['risk_level'] for pred in predictions.values()],
            'Execution Time (s)': [pred['execution_time'] for pred in predictions.values()]
        })

        display(pred_df)

        # Visualize predictions
        plt.figure(figsize=(10, 6))
        bars = plt.barh(pred_df['Model'], pred_df['Dropout Probability'], color=['green' if p < 0.4 else 'orange' if p < 0.7 else 'red' for p in pred_df['Dropout Probability']])

        plt.title('Dropout Risk Probability by Model')
        plt.xlabel('Probability')
        plt.xlim(0, 1)

        # Add threshold lines
        plt.axvline(x=0.4, color='orange', linestyle='--', alpha=0.7, label='Medium Risk Threshold')
        plt.axvline(x=0.7, color='red', linestyle='--', alpha=0.7, label='High Risk Threshold')

        # Add probability values on bars
        for bar, prob in zip(bars, pred_df['Dropout Probability']):
            plt.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2, f'{prob:.2f}', va='center')

        plt.legend()
        plt.tight_layout()
        plt.show()

        # If XGBoost is available and used for prediction, provide SHAP explanation
        if 'xgboost' in self.models and self.explainer is not None:
            print("\nExplanation for XGBoost prediction:")

            # Calculate SHAP values
            if isinstance(student_data, pd.Series):
                explanation = self.explainer.shap_values(student_data.values.reshape(1, -1))[0]
            else:
                explanation = self.explainer.shap_values(student_data.reshape(1, -1))[0]

            # Plot explanation
            plt.figure(figsize=(12, 6))
            shap.force_plot(
                base_value=self.explainer.expected_value,
                shap_values=explanation,
                features=student_data,
                feature_names=self.X_test.columns,
                matplotlib=True,
                show=False
            )
            plt.title('Factors Influencing Dropout Prediction')
            plt.tight_layout()
            plt.show()

            # Provide actionable insights
            feature_impact = pd.DataFrame({
                'Feature': self.X_test.columns,
                'Impact': explanation
            }).sort_values('Impact', ascending=False)

            # Top positive factors (increasing dropout risk)
            positive_factors = feature_impact[feature_impact['Impact'] > 0].head(5)

            # Top negative factors (decreasing dropout risk)
            negative_factors = feature_impact[feature_impact['Impact'] < 0].head(5)

            print("\nActionable Insights:")
            print("-------------------")

            if not positive_factors.empty:
                print("Top risk factors to address:")
                for i, (feature, impact) in enumerate(zip(positive_factors['Feature'], positive_factors['Impact']), 1):
                    print(f"{i}. {feature}: Contributes {impact:.4f} to dropout risk")

            if not negative_factors.empty:
                print("\nProtective factors to maintain:")
                for i, (feature, impact) in enumerate(zip(negative_factors['Feature'], negative_factors['Impact']), 1):
                    print(f"{i}. {feature}: Reduces dropout risk by {abs(impact):.4f}")

            print("\nRecommendations:")
            print("For high-risk students, consider:")
            print("1. Academic interventions targeting specific subjects")
            print("2. Increased advisor check-ins")
            print("3. Connecting to support services")
            print("4. Peer mentoring programs")
            print("5. Financial aid review if applicable")

# Main execution
if __name__ == "__main__":
    print("Student Dropout Prediction System")
    print("================================")
    print("This system uses advanced machine learning techniques to predict student dropout risk.")

    # Load dataset
    file_path = input("Please enter the path to your CSV dataset: ")
    predictor = StudentDropoutPredictor()

    if predictor.load_data(file_path):
        if predictor.preprocess_data(target_col='Target'):
            # Train models
            predictor.train_baseline_model()
            predictor.train_xgboost_model(optimize=True)
            predictor.train_lstm_model()
            # Compare models
            predictor.compare_models()
            # Predict dropout risk for a sample
            predictor.predict_dropout_risk()
        else:
            print("Data preprocessing failed.")
    else:
        print("Failed to load dataset.")